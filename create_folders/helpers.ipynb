{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%alias nb_convert ~/bin/develtools/nbconvert helpers.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/aaronciuffo/bin/develtools/nbconvert, helpers.ipynb,\n",
      "[NbConvertApp] Converting notebook helpers.ipynb to python\n"
     ]
    }
   ],
   "source": [
    "%nb_convert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import csv\n",
    "from pathlib import Path\n",
    "# import PySimpleGUI as sg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_exit(e='unknown error in unknown module!', exit_status=99, ret_value=None):\n",
    "    '''handle exits and return exit function with either a soft_exit or hard_exit -\n",
    "        The returned function can be executed by the calling process when it is ready \n",
    "        rather than forcing an exit immediately \n",
    "    \n",
    "        soft_exit prints message and optionally logs message\n",
    "        hard_exit prints message, logs and calls sys.exit(exit_status)\n",
    "    \n",
    "    Args:\n",
    "        e(`str`): error or message detailing reason for exiting\n",
    "        exit_status(int): exit value --\n",
    "            0: soft_exit with no logging -- normal exit with no issues\n",
    "            1: soft_exit with logging -- exit due to recoverable issue\n",
    "            >1: hard_exit with logging -- abort execution with sys.exit(exit_status)\n",
    "            \n",
    "    Returns:\n",
    "        function: soft_exit, hard_exit'''\n",
    "    help_msg = f'try:\\n{sys.argv[0]} -h for help'\n",
    "    def hard_exit():\n",
    "        print(e)\n",
    "        sys.exit(exit_status)\n",
    "        \n",
    "    def soft_exit():\n",
    "        print(e)\n",
    "        return(e)\n",
    "    \n",
    "    if exit_status > 1:\n",
    "        logging.error(f'fatal error:\\n\\t{e}')\n",
    "        return(hard_exit)\n",
    "    \n",
    "    if exit_status == 1:\n",
    "        logging.warning(f'exited before completion with code {exit_status}')\n",
    "        logging.warning(e)\n",
    "        print(help_msg)\n",
    "        return(soft_exit)\n",
    "    \n",
    "    if exit_status < 1:\n",
    "        logging.debug(e)\n",
    "        return(soft_exit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_to_list(file):\n",
    "    '''read csv file `file` into a list\n",
    "    \n",
    "    Guess the CSV dialect (e.g. tsv, csv, etc.)\n",
    "    \n",
    "    Returns `list`'''\n",
    "    logging.debug(f'reading {file} to list')\n",
    "    csvFile = Path(file).expanduser().absolute()\n",
    "    file_csv = []\n",
    "    # try to figure out the dialect (csv, tsv, etc.)\n",
    "    with open(csvFile, 'r') as file:\n",
    "#         dialect = csv.Sniffer().sniff(file.read(1024))\n",
    "        dialect = csv.Sniffer().sniff(file.readline())\n",
    "        file.seek(0)\n",
    "        reader = csv.reader(file, dialect)\n",
    "        for row in reader:\n",
    "            file_csv.append(row)\n",
    "\n",
    "    return file_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_headers(csv_list, expected_headers=[]):\n",
    "    '''map row 0 of a csv as formatted as a list to a dictionary of expected header values'''\n",
    "    missing_headers = []\n",
    "    header_map = {}\n",
    "    \n",
    "    csvHeader = csv_list[0]\n",
    "    logging.debug('mapping headers')\n",
    "    logging.debug('checking for missing headers')\n",
    "    for each in expected_headers:\n",
    "        if each not in csvHeader:\n",
    "            missing_headers.append(each)\n",
    "            \n",
    "    if len(missing_headers) > 0:\n",
    "        logging.warning(f'missing expected headers: {missing_headers}')\n",
    "    for index, value in enumerate(csvHeader):\n",
    "        if value in expected_headers:\n",
    "            header_map[value] = index\n",
    "        \n",
    "    logging.debug('completed mapping')\n",
    "    return(header_map, missing_headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_data(csv_list, expected_headers, header_map):\n",
    "    '''validate list items for proper data types\n",
    "         naievely attempts to coerce strings from CSV into expected_header types\n",
    "         returns a tuple of list of rows that were successfully coerced and those\n",
    "         that could not be coerced\n",
    "    \n",
    "    Args:\n",
    "        csv_list(`list` of `list`): csv as a nested list [['h1', 'h2'], ['item', 'item2']]\n",
    "        expected_headers(`dict`): {'literal_header': type} {'ClassOf':, int, 'Name', str}\n",
    "        header_map(`dict`): map of list index for each header {'h1': 0, 'h2': 5, 'hN': i}\n",
    "        \n",
    "    Returns:\n",
    "        (`tuple` of `list`): (valid_rows, invalid_rows)\n",
    "    '''\n",
    "    valid = []\n",
    "    invalid = []\n",
    "\n",
    "    for row in csv_list[1:]:\n",
    "        good_row = True\n",
    "        for k in expected_headers.keys():\n",
    "            # test for coercable types\n",
    "            try:\n",
    "                test = expected_headers[k](row[header_map[k]])\n",
    "            except (ValueError):\n",
    "#                 do_exit(f'Bad student.export: {k} contained {row[header_map[k]]}\\ncannot continue. Please try running the export again.')\n",
    "                logging.warning(f'bad row: {row}')\n",
    "                logging.warning(f'column \"{k}\" contained \"{row[header_map[k]]}\"--this should be {(expected_headers[k])}')\n",
    "                invalid.append(row)\n",
    "                good_row = False\n",
    "                break\n",
    "        if  good_row:\n",
    "            valid.append(row)\n",
    "        \n",
    "    return valid, invalid\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_handler(handler=None, new_level=None):\n",
    "    '''adjust a logging handler\n",
    "    \n",
    "    Args:\n",
    "        handler(`str`): partial string in handler name - if none, returns list of all handlers attached to root\n",
    "            '*' adjusts all handlers to new_level\n",
    "        new_level(`str`): DEBUG, INFO, WARNING, ERROR\n",
    "    \n",
    "    Returns:\n",
    "        `list`: list of handlers and levels currently set'''\n",
    "    if not handler:\n",
    "        return(logging.getLogger().handlers)\n",
    "    \n",
    "    my_handler = None    \n",
    "    for index, val in enumerate(logging.getLogger().handlers):\n",
    "        if handler == '*':\n",
    "            my_handler = logging.getLogger().handlers[index]\n",
    "        else:\n",
    "            if handler in str(val):\n",
    "                my_handler = logging.getLogger().handlers[index]\n",
    "        if my_handler:\n",
    "            logging.info(f'setting {str(my_handler)} to {new_level}')\n",
    "            my_handler.setLevel(new_level)\n",
    "        else:\n",
    "            logging.warning(f'handler: \"{handler}\" not found')\n",
    "        \n",
    "    return logging.getLogger().handlers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_writer(rows_list, path):\n",
    "    '''write a list to csv with minimal quoting \n",
    "    \n",
    "    Args:\n",
    "        rows_list(`list`): list of lists to convert to csv\n",
    "        path(`str` or `Path`): path to output file'''\n",
    "    logging.debug(f'writing csv file: {path}')\n",
    "    with open(path, 'w', newline='') as file:\n",
    "        writer = csv.writer(file, delimiter=',', quoting=csv.QUOTE_MINIMAL)\n",
    "        for each in rows_list:\n",
    "            writer.writerow(each)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def len_of_dict(my_set):\n",
    "    '''calculate the overall length of a dict of list like objects\n",
    "    \n",
    "    Args:\n",
    "        my_set(`dict` or dict-like object): dictonary to assess\n",
    "        \n",
    "    Returns:\n",
    "        int - length of all elements'''\n",
    "    total = 0\n",
    "    for each_set in my_set:\n",
    "        total = total + len(my_set[each_set])\n",
    "    return total"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "portfolioCreator-alMouNtK",
   "language": "python",
   "name": "portfoliocreator-almountk"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
