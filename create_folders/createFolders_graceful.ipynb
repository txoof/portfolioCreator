{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2\n",
    "%reload_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/aaronciuffo/bin/develtools/nbconvert, createFolders_graceful.ipynb,\n",
      "[NbConvertApp] Converting notebook createFolders_graceful.ipynb to python\n"
     ]
    }
   ],
   "source": [
    "%alias nb_convert ~/bin/develtools/nbconvert createFolders_graceful.ipynb\n",
    "%nb_convert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set up logging with cfg: /Users/aaronciuffo/Documents/src/portfolioCreator/create_folders/logging_cfg.ini, log file: /Users/aaronciuffo/createFolders.log\n"
     ]
    }
   ],
   "source": [
    "import builtins\n",
    "# # ### Fix me! REmove this!\n",
    "# from pathlib import Path\n",
    "# # ## \n",
    "try:\n",
    "    from . import constants\n",
    "except ImportError:\n",
    "    import constants\n",
    "\n",
    "# I'm not sure why this is needed, but this resolves a runtime crash when run from the command line\n",
    "# reassign the builtins.print function to bprint\n",
    "bprint = builtins.print\n",
    "\n",
    "\n",
    "# import & config logging first to prevent any sub modules from creating the root logger\n",
    "import logging\n",
    "from logging import handlers\n",
    "from logging import config\n",
    "logging.config.fileConfig(constants.logging_config, defaults={'logfile': constants.log_file} )\n",
    "# lf =  Path('~/foo.log').expanduser().absolute()\n",
    "# lc = Path('/Users/aaronciuffo/Documents/src/portfolioCreator/create_folders/logging_cfg.ini')\n",
    "# lc = constants.logging_config\n",
    "# lf = constants.log_file\n",
    "# print(f'set up logging with cfg: {lc}, log file: {lf}')\n",
    "# logging.config.fileConfig(lc, defaults={'logfile': lc})\n",
    "# logging.config.fileConfig(constants.logging_config, defaults={'logfile': p} )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from . import error_msgs\n",
    "except ImportError:\n",
    "    import error_msgs\n",
    "\n",
    "try:\n",
    "    from .helpers import *\n",
    "except ImportError:\n",
    "    from helpers import *\n",
    "\n",
    "try:\n",
    "    from .filestream import GoogleDrivePath, GDStudentPath\n",
    "except ImportError:\n",
    "    from filestream import GoogleDrivePath, GDStudentPath\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import time\n",
    "import ArgConfigParse\n",
    "import os\n",
    "import glob\n",
    "from datetime import datetime\n",
    "import textwrap\n",
    "\n",
    "from rich.console import Console\n",
    "from rich.markdown import Markdown\n",
    "import PySimpleGUI as sg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class multi_line_string():\n",
    "    '''multi-line string object \n",
    "    \n",
    "    each time  multi_line_string.string is set equal to a string, it is added to \n",
    "    the existing string with a new line character\n",
    "    \n",
    "    Properties:\n",
    "        string(`str`): string'''\n",
    "\n",
    "    def __init__(self, s=''):\n",
    "        self._string = ''\n",
    "        self.append(s)\n",
    "    \n",
    "    def __str__(self):\n",
    "        return str(self.string)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return(str(self.string))\n",
    "    \n",
    "    @property\n",
    "    def string(self):\n",
    "        return self._string\n",
    "    \n",
    "    @string.setter\n",
    "    def string(self, s):\n",
    "        self._string = s\n",
    "    \n",
    "    def append (self, s):\n",
    "        self._string = self._string + s + '\\n'\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrap_print(t='', width=None):\n",
    "    if not width:\n",
    "        width = constants.TEXT_WIDTH\n",
    "        \n",
    "    wrapper = textwrap.TextWrapper(width=width, break_long_words=False, replace_whitespace=False)\n",
    "#     pdb.set_trace()\n",
    "    result = '\\n'.join([wrapper.fill(line) for line in t.splitlines()])\n",
    "#     pdb.set_trace()\n",
    "# this causes a runtime crash; it's unclear why, but is resolved by reassigning bprint = builtins.print \n",
    "#     builtins.print(result)\n",
    "    bprint(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_cmdargs():\n",
    "    '''set known command line arguments, parse sys.argv\n",
    "    \n",
    "    Returns:\n",
    "        `dict`: nested dictionary of command line arguments that matches strcture of .ini file'''\n",
    "    args = ArgConfigParse.CmdArgs()\n",
    "    args.add_argument('-s', '--student_export', ignore_none=False, metavar='/path/to/student.export.csv', \n",
    "                      type=str, dest='student_export', help='Export from PowerSchool containing: LastFirst, ClassOf, Student_Number')\n",
    "\n",
    "    args.add_argument('-g', '--google_drive', ignore_none=True, metavar='/Volumes/GoogleDrive/Shared drives/ASH Cum Folders/folder/',\n",
    "                      type=str, dest='main__drive_path', help='Full path to Google Drive Shared Drive containing cumulative files')\n",
    "\n",
    "    args.add_argument('-l', '--log_level', ignore_none=True, metavar='ERROR, WARNING, INFO, DEBUG', \n",
    "                      type=str, dest='main__log_level', help='Logging level -- Default: WARNING')\n",
    "    args.add_argument('-v', '--version', dest='version', action='store_true',\n",
    "                      default=False, help='Print version number and exit')\n",
    "    \n",
    "    args.add_argument('--more_help', dest='more_help', action='store_true',\n",
    "                       default=False, help='Print extened help and exit')\n",
    "\n",
    "    args.parse_args()\n",
    "    return args.nested_opts_dict                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_config(files):\n",
    "    '''parse .ini files \n",
    "    \n",
    "    Args:\n",
    "        files(`list`): list of `str` containing files in .ini format to parse\n",
    "    \n",
    "    Returns:\n",
    "        `dict`: nested dict of configuration'''\n",
    "    parser = ArgConfigParse.ConfigFile(config_files=files, ignore_missing=True)\n",
    "    parser.parse_config()\n",
    "    \n",
    "    return parser.config_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_drive_path(drive_path=None):\n",
    "    '''check that path is a valid google drive path and contains the appropriate sentry file\n",
    "    \n",
    "    Args:\n",
    "        drive_path(`str`): path to google drive containg cummulative folders and sentry file\n",
    "    \n",
    "    Retruns:\n",
    "        `tuple` of `bool`, `str`: When true, drive is OK; when false, drive is not valid; str contains errors'''\n",
    "    # this is super redundant -- checks the following:\n",
    "    # * is a path\n",
    "    # * is a google drive path\n",
    "    # * if sentry file exists\n",
    "    # this may be a good idea considering how some users have run into many problems with this\n",
    "\n",
    "    drive_ok = True\n",
    "    msg = None\n",
    "    if not drive_path:\n",
    "        logging.info('no google drive specified')\n",
    "        drive_ok = False\n",
    "        msg = 'No Google Drive specified'\n",
    "        return drive_ok, msg\n",
    "    else:\n",
    "        drive_path = Path(drive_path)\n",
    "    \n",
    "    if not drive_path.exists():\n",
    "        logging.warning(f'specified path \"{drive_path}\" does not exist')\n",
    "        drive_ok = False\n",
    "#         msg = f'The Google Drive \"{drive_path}\" does not appear to exist on Google Drive'\n",
    "        msg = error_msgs.PATH_ERROR.format(drive_path=drive_path)\n",
    "        return drive_ok, msg\n",
    "    else:\n",
    "        google_drive = GoogleDrivePath(drive_path)\n",
    "    \n",
    "    try:\n",
    "        google_drive.get_xattr('user.drive.id')\n",
    "    except ChildProcessError as e:\n",
    "        logging.warning(f'specified path \"{drive_path}\" is not a Google Drive path')\n",
    "#         msg = f'The Google Drive \"{drive_path}\" does not appear to be a valid google Shared Drive'\n",
    "        msg = error_msgs.NON_GDRIVE_ERROR.format(drive_path=drive_path)\n",
    "        drive_ok = False\n",
    "        return drive_ok, msg\n",
    "\n",
    "    sentry_file = constants.sentry_file    \n",
    "    sentry_file_path = drive_path/Path(sentry_file)\n",
    "    \n",
    "    if not sentry_file_path.is_file():\n",
    "        logging.warning(f'sentry file is missing in specified path \"{drive_path}\"')\n",
    "        msg = error_msgs.SENTRY_ERROR.format(drive_path=drive_path, sentry_file=sentry_file)\n",
    "#         msg = f'''The file: \"{sentry_file}\" is missing from the chosen shared drive:\n",
    "# `{drive_path}`\n",
    "\n",
    "# This does not appear to be the correct folder for `Cumulative Student Folders.` \n",
    "\n",
    "# Choose a different Shared Drive with the button:\n",
    "# #######################\n",
    "# # Change Shared Drive #\n",
    "# #######################\n",
    "\n",
    "\n",
    "# If you are sure \n",
    "# `{drive_path}` \n",
    "# is correct, please contact IT Support and ask for help. \n",
    "\n",
    "# Screenshot or copy this entire text below the line and provide it to IT Support.\n",
    "# ###########################################################\n",
    "\n",
    "# IT Support:\n",
    "# {sys.argv[0]}\n",
    "# The program above uses Google File Stream to create student folders on a Google Shared Drive. The Shared Drive should contain a folder called `Student Cumulative Folders (AKA Student Portfolios)` or something similar. \n",
    "\n",
    "# The program checks for `{sentry_file}` to ensure that the user has selected the appropriate Google Shared Drive **AND** the appropriate folder.\n",
    "\n",
    "# BEFORE PROCEEDING: Confirm that {drive_path} is correct and contains the `Student Cumulative Folders (AKA Student Portfolios)` folder.\n",
    "\n",
    "# The following steps should be run on the user's computer, signed in as the user\n",
    "\n",
    "# 1) Check Google File Stream is running on the user's computer and the use is signed in\n",
    "# 2) Use Finder to verify the user has access to {drive_path}\n",
    "# 3) Check that `Student Cumulative Folders (AKA Student Portfolios)` exists on the Shared Drive above\n",
    "# 4) Open `terminal.app` and run the command below\n",
    "\n",
    "#      $ touch {drive_path}/{sentry_file}\n",
    "     \n",
    "# 5) Try running the program again'''\n",
    "        drive_ok = False\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    return drive_ok, msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_folders(drive_path, valid_rows, header_map, window=None):\n",
    "    logging.info(f'creating folders as needed in {drive_path}')\n",
    "    grade_level_dirs = constants.student_dirs\n",
    "    \n",
    "    directories = {'created': [], 'exist': [], 'duplicate': [], 'failed': [], 'multiple': [], 'subdirs': []}\n",
    "    directories_to_check = []\n",
    "\n",
    "    total = len(valid_rows)\n",
    "    print(f'{total} student directories will be checked and created if needed')\n",
    "    \n",
    "    def make_subdirs(student_dir):\n",
    "        '''helper function to create multiple child directories in `student_dir`\n",
    "        \n",
    "        Args:\n",
    "            student_dir(`GDStudent`): parent for child directories\n",
    "        \n",
    "        Returns:\n",
    "            None'''\n",
    "        logging.debug(f'checking grade level dirs for {student_dir}')\n",
    "        for gld in grade_level_dirs:\n",
    "            subdir = student_dir.mkchild(gld, exist_ok=True)\n",
    "            if not subdir.exists():\n",
    "                try:\n",
    "                    subdir.mkdir()\n",
    "                except (OSError, FileNotFoundError) as e:\n",
    "                    logging.warning(f'error creating grade level directory: {gld}: {e}')\n",
    "                    directories['failed'].append(subdir)\n",
    "                else:\n",
    "                    directories['subdirs'].append(subdir)\n",
    "            else:\n",
    "                if not subdir.confirm():\n",
    "                    logging.debug(f'exists, but is not confirmed: {subdir}')\n",
    "                    directories['subdirs'].append(subdir)\n",
    "#         return ok, failed\n",
    "                \n",
    "    \n",
    "\n",
    "    if window:\n",
    "        window.Refresh()\n",
    "    \n",
    "    # build a list of GDStudentPath objects to check for existence/creation\n",
    "    \n",
    "    logging.info(f'processing {total} rows')\n",
    "    \n",
    "    for student in valid_rows:\n",
    "        class_of = student[header_map['ClassOf']]\n",
    "        last_first = student[header_map['LastFirst']]\n",
    "        student_number = student[header_map['Student_Number']]\n",
    "        logging.debug(f'class: {class_of}, lastfirst: {last_first}, student number: {student_number}')\n",
    "        directories_to_check.append(GDStudentPath(drive_path, ClassOf=class_of, Student_Number=student_number, LastFirst=last_first))\n",
    "    \n",
    "    \n",
    "    # check for similar directories\n",
    "    for index, directory in enumerate(directories_to_check):\n",
    "        logging.debug(f'checking for existing dirs with student number: {directory.Student_Number}')\n",
    "        directory.check_similar()\n",
    "        # new directories\n",
    "        if len(directory.matches) == 0:\n",
    "            logging.debug(f'creating new directory for {directory.LastFirst}')\n",
    "            try:\n",
    "                directory.mkdir()\n",
    "            except (OSError, FileNotFoundError) as e:\n",
    "                logging.warning(f'error creating directory: {directory.path}: {e}')\n",
    "                directories['failed'].append(directory)\n",
    "            else:\n",
    "                directories['created'].append(directory)\n",
    "            \n",
    "            # queue subdirs for creation\n",
    "            make_subdirs(directory)\n",
    "                    \n",
    "        # existing directories           \n",
    "        if len(directory.matches) == 1 and not directory.duplicate:\n",
    "            logging.debug(f'existing directory for {directory.LastFirst}, this is OK')\n",
    "            directories['exist'].append(directory)\n",
    "            # queue subdirs for creation\n",
    "            make_subdirs(directory)\n",
    "        \n",
    "        if len(directory.matches) == 1 and directory.duplicate:\n",
    "            logging.warning(f'a directory already exists with a different LastFirst, but the same Student_Number; this is NOT OK')\n",
    "            logging.info('this directory will not be created')\n",
    "            directories['duplicate'].append(directory)\n",
    "            \n",
    "    \n",
    "        # directories that have multiple matches\n",
    "        if len(directory.matches) > 1:\n",
    "            logging.warning(f'{len(directory.matches)} existing directories found for {directory.LastFirst}; this is NOT OK')            \n",
    "            logging.info('this directory will not be created')            \n",
    "            directories['multiple'].append(directory) \n",
    "        print(f'{(index+1)/total*100:.0f}% completed')\n",
    "\n",
    "        if window:\n",
    "            sg.one_line_progress_meter(title='Cumulative Folder Creation', \n",
    "                                       current_value=index+1, \n",
    "                                       max_value=len(directories_to_check), \n",
    "                                       key='key',\n",
    "                                       orientation='h')\n",
    "            window.Refresh()\n",
    "\n",
    "                \n",
    "    return directories\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_folders(directories, window=None):\n",
    "    '''Verify that processed rows have synchronized over filestream\n",
    "    report on those that have failed to sync\n",
    "    \n",
    "    Args:\n",
    "        directories(`dict`): {'created': [], 'subdirs': [], 'exist': []}\n",
    "            all other keys will be returned in the unconfirmed_sets of the tuple\n",
    "        window(`PySimpleGUI window): window object; refresh after each print statement\n",
    "        \n",
    "    Returns:\n",
    "        tuple(confirmed_sets, unconfirmed_sets)'''\n",
    "    # try to confirm created files N times before giving up\n",
    "    confirm_retry = constants.confirm_retry\n",
    "    #  wait N seconds for first try, N*retry for each subsiquent retry\n",
    "    base_wait = constants.base_wait  \n",
    "    checks_complete = False\n",
    "    \n",
    "    sets_to_check = ['created', 'subdirs', 'exist']\n",
    "    \n",
    "    unconfirmed_sets = {}\n",
    "    confirmed_sets = {}    \n",
    "    \n",
    "    for each_set in directories:\n",
    "        if not each_set in sets_to_check:\n",
    "            unconfirmed_sets[each_set] = set(directories[each_set])\n",
    "    \n",
    "    for each_set in sets_to_check:\n",
    "        unconfirmed_sets[each_set] = set(directories[each_set])\n",
    "        confirmed_sets[each_set] = set()\n",
    "\n",
    "    \n",
    "    for i in range(0, confirm_retry):\n",
    "        logging.info(f'checking student directories: attempt {i+1} of {confirm_retry}')\n",
    "        unconfirmed_dir_total = 0\n",
    "        print(f'attempt {i+1} of {confirm_retry}')\n",
    "        \n",
    "        delay = base_wait * i\n",
    "        if i > 0:\n",
    "            logging.info(f'pausing {delay} seconds before checking again ')\n",
    "            print(f'pausing for {delay} seconds')\n",
    "            time.sleep(delay)\n",
    "            \n",
    "        if window:\n",
    "            window.Refresh()\n",
    "            \n",
    "        for each_set in sets_to_check:\n",
    "            logging.debug(f'verifying set: {each_set}')\n",
    "            confirmed_dirs = set()\n",
    "            for each_dir in unconfirmed_sets[each_set]:\n",
    "                logging.debug(f'checking {each_dir}')\n",
    "                if each_dir.confirm():\n",
    "                    logging.debug('confirmed')\n",
    "                    confirmed_dirs.add(each_dir)\n",
    "            unconfirmed_sets[each_set].difference_update(confirmed_dirs)\n",
    "            confirmed_sets[each_set].update(confirmed_dirs)\n",
    "        \n",
    "        for each_set in sets_to_check:\n",
    "            unconfirmed_dir_total = unconfirmed_dir_total + len(unconfirmed_sets[each_set])\n",
    "        logging.debug(f'{unconfirmed_dir_total} directories remain unconfirmed')\n",
    "        \n",
    "        if unconfirmed_dir_total <= 0:\n",
    "            print(f'all folders confirmed')\n",
    "            break\n",
    "        print(f'{unconfirmed_dir_total} remain to be checked')\n",
    "        if window:\n",
    "            window.Refresh()\n",
    "    \n",
    "    return confirmed_sets, unconfirmed_sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_csv(confirmed, unconfirmed, invalid_list, csv_output_path=None):\n",
    "    '''write out processed directories to a CSV file for import into PowerSchool SIS\n",
    "    \n",
    "    Args:\n",
    "        confirmed(`dict` of `set`): directories that were created and confirmed to exist\n",
    "        unconfirmed(`dict` of `set`): directories that were created and could not be confirmed\n",
    "        invlaid_list('list'): rows from imported csv that contained bad data types \n",
    "        output_path(`str`): override default directory pulled from constants.csv_output_path \n",
    "            to use for output of CSV file\n",
    "        \n",
    "    Returns:\n",
    "        `tuple` of path to confirmed and unconfirmed csv files'''\n",
    "    \n",
    "    \n",
    "    \n",
    "    if csv_output_path:\n",
    "        csv_output_path = Path(csv_output_path)\n",
    "    else:\n",
    "        csv_output_path = constants.csv_output_path\n",
    "        \n",
    "        \n",
    "    if not csv_output_path.exists():\n",
    "        logging.info(f'creating output directory: {csv_output_path}')\n",
    "        try:\n",
    "            csv_output_path.mkdir(parents=True, exist_ok=True)\n",
    "        except Exception as e:\n",
    "            do_exit(e, 1)\n",
    "        \n",
    "    date = datetime.now().strftime(constants.date_format)\n",
    "    \n",
    "    confirmed_file = f'{constants.csv_output_name}'.format(date=date)\n",
    "    unconfirmed_file = f'{constants.csv_error_name}'.format(date=date)\n",
    "    invalid_file = f'{constants.csv_invalid_name}'.format(date=date)\n",
    "    \n",
    "    # handle confirmed directories\n",
    "    csv_output_headers = constants.csv_output_headers\n",
    "    csv_output_list = []\n",
    "    \n",
    "    confirmed_dirs = confirmed['created']\n",
    "    confirmed_dirs.update(confirmed['exist'])\n",
    "    \n",
    "    logging.info('processing confirmed directories')\n",
    "    # add the headers to the list\n",
    "    csv_output_list.append(list(csv_output_headers.keys()))\n",
    "    for each_dir in confirmed_dirs:\n",
    "        row = []\n",
    "        for column in csv_output_headers:\n",
    "            # retreive a property from an object using a string\n",
    "            # https://stackoverflow.com/qu            \n",
    "            object_property = getattr(each_dir, column)\n",
    "            # create a formatted string based on prop value and formatter from headers dict\n",
    "            formatted_string = f'{csv_output_headers[column]}'.format(val=object_property)\n",
    "            row.append(formatted_string)\n",
    "        csv_output_list.append(row)\n",
    "    try:\n",
    "        csv_writer(csv_output_list, csv_output_path/confirmed_file)\n",
    "    except Exception as e:\n",
    "        logging.warning(f'{e}')    \n",
    "        \n",
    "    # handle unconfirmed directories\n",
    "    csv_error_headers = constants.csv_error_headers\n",
    "    csv_error_strings = constants.csv_error_strings\n",
    "    csv_error_list = []\n",
    "\n",
    "    # add the headers to the output file\n",
    "    csv_error_list.append(list(csv_error_headers.keys()))\n",
    "\n",
    "    for each_set in unconfirmed:\n",
    "        if each_set in csv_error_strings:\n",
    "            logging.debug(f'processing unconfirmed set: {each_set}')\n",
    "            for each_dir in unconfirmed[each_set]:\n",
    "                logging.debug(f'processing: {each_dir}')\n",
    "                row = []\n",
    "                for column in csv_error_headers:\n",
    "                    try:\n",
    "                        object_property = getattr(each_dir, column)\n",
    "                    except AttributeError:\n",
    "                        formatted_string = csv_error_strings[each_set]\n",
    "                    else:\n",
    "                        formatted_string = f'{csv_error_headers[column]}'.format(val=object_property)\n",
    "                    row.append(formatted_string)\n",
    "                csv_error_list.append(row)\n",
    "        else:\n",
    "            # handle rows that are do not have a key\n",
    "            logging.warning(f'unknown set type in unconfirmed set: {each_set}')   \n",
    "    if len(csv_error_list) > 1:\n",
    "        logging.info('writing unconfirmed dirs csv')\n",
    "        try:\n",
    "            csv_writer(csv_error_list, csv_output_path/unconfirmed_file)\n",
    "        except Exception as e:\n",
    "            logging.warning(f'{e}')    \n",
    "    else:\n",
    "        logging.info('no unconfirmed directories found; no error output needed')\n",
    "        \n",
    "    #handle invalid rows that could not be processed due to bad or missing data\n",
    "    if len(invalid_list) > 1:\n",
    "        logging.info('writing invalid rows csv')\n",
    "        try:\n",
    "            csv_writer(invalid_list, csv_output_path/invalid_file)\n",
    "        except Exception as e:\n",
    "                logging.warning(f'{e}')\n",
    "\n",
    "    \n",
    "    return {'confirmed': csv_output_path/confirmed_file, \n",
    "            'unconfirmed': csv_output_path/unconfirmed_file, \n",
    "            'invalid': csv_output_path/invalid_file}\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def window_drive_path():\n",
    "#     '''launch an interactive window to ask user to specify a google drive shared folder'''\n",
    "#     drive_path = sg.Window(constants.app_name,\n",
    "#                           [[sg.Text ('Choose the Google Shared Drive and folder that contains student cummulative folders.')],\n",
    "#                                      [sg.In(), sg.FolderBrowse()],\n",
    "#                                      [sg.Ok(), sg.Cancel()]]).read(close=True)[1][0]\n",
    "    \n",
    "#     if drive_path:\n",
    "#         drive_path = Path(drive_path)\n",
    "#         logging.debug(f'user selected: {drive_path}')\n",
    "#     else: \n",
    "#         drive_path = None\n",
    "#         logging.info('no drive path selected')\n",
    "        \n",
    "#     return drive_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def window_drive_path():\n",
    "    drive_path = sg.popup_get_folder('Choose the Google Shared Drive **AND** folder that contains student cumulative folders.', \n",
    "                                     title='Select A Shared Drive', \n",
    "                                     initial_folder='/Volumes/GoogleDrive/',\n",
    "                                     keep_on_top=True, font=constants.FONT, location=constants.WIN_LOCATION)\n",
    "    \n",
    "    if drive_path:\n",
    "        drive_path=Path(drive_path)\n",
    "        logging.debug(f'user selected: {drive_path}')\n",
    "    else:\n",
    "        drive_path = None\n",
    "        logging.info('no drive path selected by user')\n",
    "    return drive_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def window_csv_file():\n",
    "    '''launch an interactive window to ask user to specify a student export file'''\n",
    "    logging.debug('launching interactive prompt for csv file')\n",
    "    csv_file = sg.popup_get_file('Select a Student Export File to Process', \n",
    "                                 title='Select A Student Export',\n",
    "                                 initial_folder=Path('~/Downloads').expanduser(),\n",
    "                                 keep_on_top=True, font=constants.FONT, location=constants.WIN_LOCATION)\n",
    "    \n",
    "    if csv_file:\n",
    "        csv_file = Path(csv_file)\n",
    "    else: \n",
    "        csv_file = None\n",
    "        logging.info('no student_export path selected')\n",
    "        \n",
    "    return csv_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_help():\n",
    "    \n",
    "    logging.debug('getting help')\n",
    "    console = Console()\n",
    "    console.options.max_width = constants.TEXT_WIDTH\n",
    "    try:\n",
    "        with open(constants.HELP_FILE) as help_file:\n",
    "            markdown = Markdown(help_file.read())\n",
    "    except Exception as e:\n",
    "        logging.error(e)\n",
    "        return do_exit(f'Error getting help!\\n{e}', 1)\n",
    "    \n",
    "    console.print(markdown)\n",
    "#     return do_exit(' ', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_program(interactive=False, window=None):\n",
    "    # set the local logger\n",
    "    logger = logging.getLogger(__name__)\n",
    "    logging.info('*'*50+'\\n')\n",
    "\n",
    "    version_info = f'{constants.app_name} version: {constants.version}\\n{constants.contact}\\n{constants.git_repo}'\n",
    "    logging.debug(version_info)    \n",
    "    logging.debug(f'python version: {sys.version}')\n",
    "    \n",
    "    # base configuration fle\n",
    "    config_file = Path(constants.config_file)\n",
    "    # user config file (~/.config/app_name/app.ini)\n",
    "    user_config_path = Path(constants.user_config_path)\n",
    "    \n",
    "    # if the user configuration file is missing set to True & create later at end\n",
    "    update_user_config = not(user_config_path.exists)\n",
    "    logging.debug(f'user config will be created: {update_user_config}')\n",
    "\n",
    "    # parse command line and config files - \n",
    "    cmd_args_dict = parse_cmdargs()\n",
    "    cfg_files_dict = read_config([constants.config_file, constants.user_config_path])\n",
    "\n",
    "    # merge the command line arguments and the config files; cmd line overwrites files\n",
    "    config = ArgConfigParse.merge_dict(cfg_files_dict, cmd_args_dict)    \n",
    "\n",
    "    logging.debug('processing command line options')\n",
    "    \n",
    "    if config['__cmd_line']['version']:\n",
    "        logging.debug('display version and exit')\n",
    "        return do_exit(version_info, 0)\n",
    "    \n",
    "    if config['__cmd_line']['more_help'] and not interactive:\n",
    "        logging.debug('display help and exit')\n",
    "        print_help()\n",
    "        return do_exit(' ', 0)\n",
    "\n",
    "    \n",
    "    # handle missing google shared drive paths\n",
    "    if not config['main']['drive_path']:\n",
    "        if interactive:\n",
    "            print('No Google Shared Drive has been set yet.')\n",
    "            print('Locate the proper Google Shared Drive **and** then locate the `Student Cumulative Folders (AKA Student Portfolios)` folder')\n",
    "            drive_path_interactive = window_drive_path()\n",
    "            if not drive_path_interactive: \n",
    "                return do_exit('Please choose a Google Shared Drive to proceed', 0)\n",
    "            else:\n",
    "                config['main']['drive_path'] = drive_path_interactive\n",
    "                update_user_config = True\n",
    "                \n",
    "        if not interactive:\n",
    "            return (do_exit(f'Can not run without a Google Shared Drive Configured.\\ntry:\\n{sys.argv[0]} -h for help', 1))\n",
    "    \n",
    "    # adjust logging levels if needed\n",
    "    if config['main']['log_level']:\n",
    "        ll = config['main']['log_level']\n",
    "        if ll in (['DEBUG', 'INFO', 'WARNING', 'ERROR']):\n",
    "            logging.root.setLevel(ll)\n",
    "            handlers = adjust_handler ('*', ll)\n",
    "            logging.debug(f'adjusted log levels: {handlers} to {ll}')\n",
    "        else:\n",
    "            logging.warning(f'unknown or invalid log_level: {ll}')\n",
    "\n",
    "    logging.debug('loading constants')\n",
    "    \n",
    "    # load file constants\n",
    "    expected_headers = constants.expected_headers    \n",
    "    student_dirs = constants.student_dirs\n",
    "    \n",
    "    # set local vars\n",
    "    drive_path = Path(config['main']['drive_path'])\n",
    "    \n",
    "    # check that supplied path is a valid cummulative folder path\n",
    "    drive_status = check_drive_path(drive_path)\n",
    "    if not drive_status[0]:\n",
    "        return do_exit(drive_status[1], 0)\n",
    "    \n",
    "    logging.debug(f'drive status: {drive_status}')\n",
    "\n",
    "    # get csv_file and drive path\n",
    "    if interactive:\n",
    "        print('Select a student export file to process')\n",
    "        csv_file = window_csv_file()\n",
    "        if not csv_file:\n",
    "            return do_exit('Can not proceed without a student export file.', 0)\n",
    "    else:\n",
    "        try:\n",
    "            csv_file = Path(config['__cmd_line']['student_export'])\n",
    "        except TypeError:\n",
    "            return do_exit('No student export file specified on command line', 1)\n",
    "        \n",
    "    if not csv_file:\n",
    "        return do_exit('Student export file missing', 1)\n",
    "    \n",
    "    logging.debug(f'processing csv file: {csv_file}')\n",
    "    # read the CSV file\n",
    "    try:\n",
    "        print(f'Processing {csv_file}...')\n",
    "        csv_list = csv_to_list(csv_file)\n",
    "    except (FileNotFoundError, OSError, IOError, TypeError) as e:\n",
    "        logging.error(f'could not read csv file: {csv_file.name}')\n",
    "        logging.error(e)\n",
    "        return do_exit(e, 1)\n",
    "    except csv.Error as e:\n",
    "        logging.error(f'could not process csv file: {csv_file.name}')\n",
    "        logging.error(e)\n",
    "        return do_exit(e, 1)\n",
    "    finally:\n",
    "        print('done processing')\n",
    "        \n",
    "    if interactive:\n",
    "        window.Refresh()\n",
    "   \n",
    "    # map the headers \n",
    "    print(f'checking for appropriate column headers')\n",
    "    header_map, missing_headers = map_headers(csv_list, expected_headers.keys())\n",
    "    \n",
    "    if len(missing_headers) > 0:\n",
    "        return do_exit(f'{csv_file.name} is missing one or more column headers:\\n{missing_headers}\\n\\ncan not proceed with this file', 0)\n",
    "    \n",
    "    # validate rows in the CSV file\n",
    "    print(f'checking each row for valid data')\n",
    "    valid_rows, invalid_rows = validate_data(csv_list, expected_headers, header_map)\n",
    "    print(f'{len(valid_rows)} student rows were found and will be processed')\n",
    "    print(f'{len(invalid_rows)} improperly formatted student rows were found and will be skipped')\n",
    "    \n",
    "    if interactive:\n",
    "        window.Refresh()\n",
    "    \n",
    "    # insert the header into the invalid_rows for later output\n",
    "    invalid_rows.insert(0, csv_list[0])\n",
    "    \n",
    "    print(f'\\nPreparing to process and create student folders for {len(valid_rows)} students')\n",
    "    print(f'using Google Shared Drive: {drive_path}')\n",
    "    print(f'this could take some time...')\n",
    "    \n",
    "    if interactive:\n",
    "        window.Refresh()\n",
    "    \n",
    "    directories = create_folders(drive_path=drive_path, valid_rows=valid_rows, header_map=header_map, window=window)\n",
    "    \n",
    "    \n",
    "    print(f'Confirming that student folders were properly created in the cloud')\n",
    "    confirmed_dirs, unconfirmed_dirs = check_folders(directories, window=window)\n",
    "    \n",
    "    \n",
    "#     return directories, confirmed_dirs, unconfirmed_dirs    \n",
    "    \n",
    "    print('Preparing records...')\n",
    "    if interactive:\n",
    "        window.Refresh()\n",
    "    csv_files = write_csv(confirmed_dirs, unconfirmed_dirs, invalid_rows)\n",
    "    \n",
    "\n",
    "    \n",
    "    if update_user_config:\n",
    "        try:\n",
    "            logging.info(f'updating user configuration file: {user_config_path}')\n",
    "            ArgConfigParse.write(config, user_config_path, create=True)\n",
    "        except Exception as e:\n",
    "            m = f'Error updating user configuration file: {e}'\n",
    "            do_exit(m, 1)    \n",
    "    \n",
    "    \n",
    "    len_confirmed = len_of_dict(confirmed_dirs)\n",
    "    len_unconfirmed = len_of_dict(unconfirmed_dirs)\n",
    "    \n",
    "    s = multi_line_string()\n",
    "    \n",
    "    s.append('*****Summary*****')\n",
    "    s.append(f'Processed {len(csv_list)-1} student recods from \"{csv_file}\"')\n",
    "    s.append(f'{len(valid_rows)} rows contained valid data and were processed')\n",
    "    if len_confirmed > 0:\n",
    "        s.append('-'*10)\n",
    "        t_str = csv_files[\"confirmed\"]\n",
    "        s.append(f'\\nsend the file below with the PowerSchool Administrator for import')\n",
    "        s.append(f'*************************\\n')\n",
    "        s.append(f'{t_str}')\n",
    "        s.append(f'\\n*************************')\n",
    "    \n",
    "    if len_unconfirmed > 0:\n",
    "        t_str = csv_files[\"unconfirmed\"]\n",
    "        s.append('-'*10)\n",
    "        s.append(f'{len_unconfirmed} rows could not be confirmed')\n",
    "        s.append(f'review the file below for more information on the failed rows:')\n",
    "        s.append(f'*************************\\n')\n",
    "        s.append(f'{t_str}')\n",
    "        s.append(f'\\n*************************')\n",
    "    \n",
    "    if len(invalid_rows) > 1:\n",
    "        s.append('-'*10)\n",
    "        s.append(f'{len(invalid_rows)-1} rows contained invalid data and were skipped')\n",
    "        s.append('please ONLY use student.export files produced by PowerSchool')\n",
    "        t_str = csv_files[\"invalid\"]\n",
    "        s.append(f'review the file below for more information on the invalid rows:')\n",
    "        s.append(f'*************************\\n')\n",
    "        s.append(f'{t_str}')\n",
    "        s.append(f'\\n*************************')\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "    print(s.string)\n",
    "    if interactive:\n",
    "        window.Refresh()\n",
    "    \n",
    "    if interactive:\n",
    "        sg.popup(s, title='Summary', font=constants.FONT, keep_on_top=True)\n",
    "    \n",
    "\n",
    "    logging.debug('done')\n",
    "    \n",
    "    return do_exit('Done - Ready to process another file', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    '''launch the cli or gui version of the script '''\n",
    "    run_gui = False\n",
    "    if len(sys.argv) <= 1:\n",
    "        run_gui = True\n",
    "\n",
    "    if '-f' in sys.argv:\n",
    "        logging.debug('likely running in a jupyter environment')\n",
    "        run_gui = True\n",
    "\n",
    "\n",
    "    if run_gui:\n",
    "        # set the global constant for text width\n",
    "        TEXT_WIDTH = constants.TEXT_WIDTH\n",
    "        FONT = constants.FONT\n",
    "\n",
    "        # create a wrapper that matches the text output size\n",
    "        logging.debug('redefining `print` to use `wrap_print`')\n",
    "        print = wrap_print\n",
    "        version_info = f'{constants.app_name} version: {constants.version}\\n{constants.contact}\\n{constants.git_repo}'\n",
    "\n",
    "        def text_fmt(text, *args, **kwargs): return sg.Text(text, *args, **kwargs)\n",
    "        layout =[ [text_fmt('Cumulative Portfolio Creator', font=f'{constants.FONT_FACE} {constants.FONT_SIZE+2}')],             \n",
    "          [text_fmt(version_info, font=f'{constants.FONT_FACE} {constants.FONT_SIZE}')],\n",
    "          [sg.Text('Create Cumulative Folders on Google Shared Drive', font=f'{constants.FONT_FACE} {constants.FONT_SIZE}')],\n",
    "          [sg.Output(size=(TEXT_WIDTH+30, 40), font=FONT)],\n",
    "          [sg.Button('Process File', font=FONT), sg.Button('Change Shared Drive', font=FONT), sg.Button('Help', font=FONT), sg.Button('Exit', font=FONT)],\n",
    "                ]\n",
    "\n",
    "        window = sg.Window('Cumulative Portfolio Creator', layout=layout, keep_on_top=False, location=constants.WIN_LOCATION)\n",
    "\n",
    "        bprint('Choose a file to process...')\n",
    "        window.Refresh()\n",
    "\n",
    "        while True:\n",
    "\n",
    "            window.finalize()\n",
    "            window.BringToFront()\n",
    "            (event, value) = window.read()\n",
    "\n",
    "            if event == 'Exit' or event == sg.WIN_CLOSED:\n",
    "                break\n",
    "            if event == 'Process File':\n",
    "                ret_val = main_program(run_gui, window)\n",
    "                ret_val()\n",
    "            if event == 'Change Shared Drive':\n",
    "                drive = window_drive_path()\n",
    "                if drive:\n",
    "                    sys.argv.append('-g')\n",
    "                    sys.argv.append(str(drive))\n",
    "                    print(f'Shared drive will be updated to\\n{drive}\\non next execution.')\n",
    "                    window.Refresh()\n",
    "                else:\n",
    "                    print('Shared drive will not be updated')\n",
    "            if event == 'Help':\n",
    "                print_help()\n",
    "                window.Refresh()\n",
    "        window.close()\n",
    "        sg.easy_print_close()\n",
    "\n",
    "    # run in non-interactive command line mode\n",
    "    else:\n",
    "        ret_val = main_program()\n",
    "        ret_val()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "portfolioCreator-alMouNtK",
   "language": "python",
   "name": "portfoliocreator-almountk"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
