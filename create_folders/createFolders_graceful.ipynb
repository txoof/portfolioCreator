{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2\n",
    "%reload_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/aaronciuffo/bin/develtools/nbconvert, createFolders_graceful.ipynb,\n",
      "[NbConvertApp] Converting notebook createFolders_graceful.ipynb to python\n"
     ]
    }
   ],
   "source": [
    "%alias nb_convert ~/bin/develtools/nbconvert createFolders_graceful.ipynb\n",
    "%nb_convert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import constants\n",
    "# import class_constants\n",
    "# import & config logging first to prevent any sub modules from creating the root logger\n",
    "import logging\n",
    "from logging import handlers\n",
    "from logging import config\n",
    "logging.config.fileConfig(constants.logging_config, defaults={'logfile': constants.log_file} )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers import *\n",
    "\n",
    "from filestream import GoogleDrivePath, GDStudentPath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import time\n",
    "import ArgConfigParse\n",
    "import os\n",
    "import glob\n",
    "from datetime import datetime\n",
    "import PySimpleGUI as sg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_cmdargs():\n",
    "    '''set known command line arguments, parse sys.argv\n",
    "    \n",
    "    Returns:\n",
    "        `dict`: nested dictionary of command line arguments that matches strcture of .ini file'''\n",
    "    args = ArgConfigParse.CmdArgs()\n",
    "    args.add_argument('-s', '--student_export', ignore_none=False, metavar='/path/to/student.export.csv', \n",
    "                      type=str, dest='student_export', help='Export from PowerSchool containing: LastFirst, ClassOf, Student_Number')\n",
    "\n",
    "    args.add_argument('-g', '--google_drive', ignore_none=True, metavar='/Volumes/GoogleDrive/Shared drives/ASH Cum Folders/folder/',\n",
    "                      type=str, dest='main__drive_path', help='Full path to Google Drive Shared Drive containing cumulative files')\n",
    "\n",
    "    args.add_argument('-l', '--log_level', ignore_none=True, metavar='ERROR, WARNING, INFO, DEBUG', \n",
    "                      type=str, dest='main__log_level', help='Logging level -- Default: WARNING')\n",
    "    args.add_argument('-v', '--version', dest='version', action='store_true',\n",
    "                      default=False, help='Print version number and exit')\n",
    "\n",
    "    args.parse_args()\n",
    "    return args.nested_opts_dict                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_config(files):\n",
    "    '''parse .ini files \n",
    "    \n",
    "    Args:\n",
    "        files(`list`): list of `str` containing files in .ini format to parse\n",
    "    \n",
    "    Returns:\n",
    "        `dict`: nested dict of configuration'''\n",
    "    parser = ArgConfigParse.ConfigFile(config_files=files, ignore_missing=True)\n",
    "    parser.parse_config()\n",
    "    \n",
    "    return parser.config_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_drive_path(drive_path=None):\n",
    "    '''check that path is a valid google drive path and contains the appropriate sentry file\n",
    "    \n",
    "    Args:\n",
    "        drive_path(`str`): path to google drive containg cummulative folders and sentry file\n",
    "    \n",
    "    Retruns:\n",
    "        `tuple` of `bool`, `str`: When true, drive is OK; when false, drive is not valid; str contains errors'''\n",
    "    # this is super redundant -- checks the following:\n",
    "    # * is a path\n",
    "    # * is a google drive path\n",
    "    # * if sentry file exists\n",
    "    # this may be a good idea considering how some users have run into many problems with this\n",
    "\n",
    "    drive_ok = True\n",
    "    msg = None\n",
    "    if not drive_path:\n",
    "        logging.info('no google drive specified')\n",
    "        drive_ok = False\n",
    "        msg = 'No Google Drive specified'\n",
    "        return drive_ok, msg\n",
    "    else:\n",
    "        drive_path = Path(drive_path)\n",
    "    \n",
    "    if not drive_path.exists():\n",
    "        logging.warning(f'specified path \"{drive_path}\" does not exist')\n",
    "        drive_ok = False\n",
    "        msg = f'The Google Drive \"{drive_path}\" does not appear to exist on Google Drive'\n",
    "        return drive_ok, msg\n",
    "    else:\n",
    "        google_drive = GoogleDrivePath(drive_path)\n",
    "    \n",
    "    try:\n",
    "        google_drive.get_xattr('user.drive.id')\n",
    "    except ChildProcessError as e:\n",
    "        logging.warning(f'specified path \"{drive_path}\" is not a Google Drive path')\n",
    "        msg = f'The Google Drive \"{drive_path}\" does not appear to be a valid google Shared Drive'\n",
    "        drive_ok = False\n",
    "        return drive_ok, msg\n",
    "\n",
    "    sentry_file = constants.sentry_file    \n",
    "    sentry_file_path = drive_path/Path(sentry_file)\n",
    "    \n",
    "    if not sentry_file_path.is_file():\n",
    "        logging.warning(f'sentry file is missing in specified path \"{drive_path}\"')\n",
    "        msg = f'''The chosen google shared drive \"{drive_path}\"\n",
    "does not appear to be a Cumulative Student Folder. \n",
    "\n",
    "The file: \"{sentry_file}\" is missing. \n",
    "If you are sure {drive_path} is correct, \n",
    "please contact IT Support and askfor help. \n",
    "\n",
    "Please screenshot or copy this entire text below and provide it to IT Support.\n",
    "\n",
    "###############################################################################\n",
    "Run the command below from the terminal of the user that submitted this ticket.\n",
    "This command will create the necessary files for this script. \n",
    "\n",
    "Confirm that {drive_path} is the correct\n",
    "Google Shared Drive for Cumulative Student Folders BEFORE proceeding.\n",
    "     $ touch {drive_path}/{sentry_file}'''\n",
    "        drive_ok = False\n",
    "    \n",
    "    \n",
    "    \n",
    "    return drive_ok, msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_drive_path(drive_path=None):\n",
    "    '''check that path is a valid google drive path and contains the appropriate sentry file\n",
    "    \n",
    "    Args:\n",
    "        drive_path(`str`): path to google drive containg cummulative folders and sentry file\n",
    "    \n",
    "    Retruns:\n",
    "        `tuple` of `bool`, `str`: When true, drive is OK; when false, drive is not valid; str contains errors'''\n",
    "    # this is super redundant -- checks the following:\n",
    "    # * is a path\n",
    "    # * is a google drive path\n",
    "    # * if sentry file exists\n",
    "    # this may be a good idea considering how some users have run into many problems with this\n",
    "\n",
    "    drive_ok = True\n",
    "    msg = None\n",
    "    if not drive_path:\n",
    "        logging.info('no google drive specified')\n",
    "        drive_ok = False\n",
    "        msg = 'No Google Drive specified'\n",
    "        return drive_ok, msg\n",
    "    else:\n",
    "        drive_path = Path(drive_path)\n",
    "    \n",
    "    if not drive_path.exists():\n",
    "        logging.warning(f'specified path \"{drive_path}\" does not exist')\n",
    "        drive_ok = False\n",
    "        msg = f'The Google Drive \"{drive_path}\" does not appear to exist on Google Drive'\n",
    "        return drive_ok, msg\n",
    "    else:\n",
    "        google_drive = GoogleDrivePath(drive_path)\n",
    "    \n",
    "    try:\n",
    "        google_drive.get_xattr('user.drive.id')\n",
    "    except ChildProcessError as e:\n",
    "        logging.warning(f'specified path \"{drive_path}\" is not a Google Drive path')\n",
    "        msg = f'The Google Drive \"{drive_path}\" does not appear to be a valid google Shared Drive'\n",
    "        drive_ok = False\n",
    "        return drive_ok, msg\n",
    "\n",
    "    sentry_file = constants.sentry_file    \n",
    "    sentry_file_path = drive_path/Path(sentry_file)\n",
    "    \n",
    "    if not sentry_file_path.is_file():\n",
    "        logging.warning(f'sentry file is missing in specified path \"{drive_path}\"')\n",
    "        msg = f'''The chosen google shared drive \"{drive_path}\"\n",
    "does not appear to be a Cumulative Student Folder. \n",
    "\n",
    "The file: \"{sentry_file}\" is missing. \n",
    "If you are sure {drive_path} is correct, \n",
    "please contact IT Support and askfor help. \n",
    "\n",
    "Please screenshot or copy this entire text below and provide it to IT Support.\n",
    "\n",
    "###############################################################################\n",
    "Run the command below from the terminal of the user that submitted this ticket.\n",
    "This command will create the necessary files for this script. \n",
    "\n",
    "Confirm that {drive_path} is the correct\n",
    "Google Shared Drive for Cumulative Student Folders BEFORE proceeding.\n",
    "     $ touch {drive_path}/{sentry_file}'''\n",
    "        drive_ok = False\n",
    "    \n",
    "    \n",
    "    \n",
    "    return drive_ok, msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_folders(directories):\n",
    "    '''Verify that processed rows have synchronized over filestream\n",
    "    report on those that have failed to sync\n",
    "    \n",
    "    Args:\n",
    "        directories(`dict`): {'created': [], 'subdirs': [], 'exist': []}\n",
    "            all other keys will be returned in the unconfirmed_sets of the tuple\n",
    "        \n",
    "    Returns:\n",
    "        tuple(confirmed_sets, unconfirmed_sets)'''\n",
    "    # try to confirm created files N times before giving up\n",
    "    confirm_retry = constants.confirm_retry\n",
    "    #  wait N seconds for first try, N*retry for each subsiquent retry\n",
    "    base_wait = constants.base_wait  \n",
    "    checks_complete = False\n",
    "    \n",
    "    sets_to_check = ['created', 'subdirs', 'exist']\n",
    "    \n",
    "    unconfirmed_sets = {}\n",
    "    confirmed_sets = {}    \n",
    "    \n",
    "    for each_set in directories:\n",
    "        if not each_set in sets_to_check:\n",
    "            unconfirmed_sets[each_set] = set(directories[each_set])\n",
    "    \n",
    "    for each_set in sets_to_check:\n",
    "        unconfirmed_sets[each_set] = set(directories[each_set])\n",
    "        confirmed_sets[each_set] = set()\n",
    "\n",
    "\n",
    "    for i in range(0, confirm_retry):        \n",
    "        logging.info(f'checking student directories: attempt {i+1} of {confirm_retry}')\n",
    "        unconfirmed_dir_total = 0\n",
    "        delay = base_wait * i\n",
    "        if i > 0:\n",
    "            logging.info(f'pausing {delay} seconds before checking again ')\n",
    "            time.sleep(delay)\n",
    "        \n",
    "        for each_set in sets_to_check:\n",
    "            logging.debug(f'verifying set: {each_set}')\n",
    "            confirmed_dirs = set()\n",
    "            for each_dir in unconfirmed_sets[each_set]:\n",
    "                logging.debug(f'checking {each_dir}')\n",
    "                if each_dir.confirm():\n",
    "                    logging.debug('confirmed')\n",
    "                    confirmed_dirs.add(each_dir)\n",
    "            unconfirmed_sets[each_set].difference_update(confirmed_dirs)\n",
    "            confirmed_sets[each_set].update(confirmed_dirs)\n",
    "        \n",
    "        for each_set in sets_to_check:\n",
    "            unconfirmed_dir_total = unconfirmed_dir_total + len(unconfirmed_sets[each_set])\n",
    "        logging.debug(f'{unconfirmed_dir_total} directories remain unconfirmed')\n",
    "        \n",
    "        if unconfirmed_dir_total <= 0:\n",
    "            break\n",
    "            \n",
    "    return confirmed_sets, unconfirmed_sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_csv(confirmed, unconfirmed, invalid_list, csv_output_path=None):\n",
    "    '''write out processed directories to a CSV file for import into PowerSchool SIS\n",
    "    \n",
    "    Args:\n",
    "        confirmed(`dict` of `set`): directories that were created and confirmed to exist\n",
    "        unconfirmed(`dict` of `set`): directories that were created and could not be confirmed\n",
    "        invlaid_list('list'): rows from imported csv that contained bad data types \n",
    "        output_path(`str`): override default directory pulled from constants.csv_output_path \n",
    "            to use for output of CSV file\n",
    "        \n",
    "    Returns:\n",
    "        `tuple` of path to confirmed and unconfirmed csv files'''\n",
    "    \n",
    "    \n",
    "    \n",
    "    if csv_output_path:\n",
    "        csv_output_path = Path(csv_output_path)\n",
    "    else:\n",
    "        csv_output_path = constants.csv_output_path\n",
    "        \n",
    "        \n",
    "    if not csv_output_path.exists():\n",
    "        logging.info(f'creating output directory: {csv_output_path}')\n",
    "        try:\n",
    "            csv_output_path.mkdir(parents=True, exist_ok=True)\n",
    "        except Exception as e:\n",
    "            do_exit(e, 1)\n",
    "        \n",
    "    date = datetime.now().strftime(constants.date_format)\n",
    "    \n",
    "    confirmed_file = f'{constants.csv_output_name}'.format(date=date)\n",
    "    unconfirmed_file = f'{constants.csv_error_name}'.format(date=date)\n",
    "    invalid_file = f'{constants.csv_invalid_name}'.format(date=date)\n",
    "    \n",
    "    # handle confirmed directories\n",
    "    csv_output_headers = constants.csv_output_headers\n",
    "    csv_output_list = []\n",
    "    \n",
    "    confirmed_dirs = confirmed['created']\n",
    "    confirmed_dirs.update(confirmed['exist'])\n",
    "    \n",
    "    logging.info('processing confirmed directories')\n",
    "    # add the headers to the list\n",
    "    csv_output_list.append(list(csv_output_headers.keys()))\n",
    "    for each_dir in confirmed_dirs:\n",
    "        row = []\n",
    "        for column in csv_output_headers:\n",
    "            # retreive a property from an object using a string\n",
    "            # https://stackoverflow.com/qu            \n",
    "            object_property = getattr(each_dir, column)\n",
    "            # create a formatted string based on prop value and formatter from headers dict\n",
    "            formatted_string = f'{csv_output_headers[column]}'.format(val=object_property)\n",
    "            row.append(formatted_string)\n",
    "        csv_output_list.append(row)\n",
    "    try:\n",
    "        csv_writer(csv_output_list, csv_output_path/confirmed_file)\n",
    "    except Exception as e:\n",
    "        logging.warning(f'{e}')    \n",
    "        \n",
    "    # handle unconfirmed directories\n",
    "    csv_error_headers = constants.csv_error_headers\n",
    "    csv_error_strings = constants.csv_error_strings\n",
    "    csv_error_list = []\n",
    "\n",
    "    # add the headers to the output file\n",
    "    csv_error_list.append(list(csv_error_headers.keys()))\n",
    "\n",
    "    for each_set in unconfirmed:\n",
    "        if each_set in csv_error_strings:\n",
    "            logging.debug(f'processing unconfirmed set: {each_set}')\n",
    "            for each_dir in unconfirmed[each_set]:\n",
    "                logging.debug(f'processing: {each_dir}')\n",
    "                row = []\n",
    "                for column in csv_error_headers:\n",
    "                    try:\n",
    "                        object_property = getattr(each_dir, column)\n",
    "                    except AttributeError:\n",
    "                        formatted_string = csv_error_strings[each_set]\n",
    "                    else:\n",
    "                        formatted_string = f'{csv_error_headers[column]}'.format(val=object_property)\n",
    "                    row.append(formatted_string)\n",
    "                csv_error_list.append(row)\n",
    "        else:\n",
    "            # handle rows that are do not have a key\n",
    "            logging.warning(f'unknown set type in unconfirmed set: {each_set}')   \n",
    "    if len(csv_error_list) > 1:\n",
    "        logging.info('writing unconfirmed dirs csv')\n",
    "        try:\n",
    "            csv_writer(csv_error_list, csv_output_path/unconfirmed_file)\n",
    "        except Exception as e:\n",
    "            logging.warning(f'{e}')    \n",
    "    else:\n",
    "        logging.info('no unconfirmed directories found; no error output needed')\n",
    "        \n",
    "    #handle invalid rows that could not be processed due to bad or missing data\n",
    "    if len(invalid_list) > 1:\n",
    "        logging.info('writing invalid rows csv')\n",
    "        try:\n",
    "            csv_writer(invalid_list, csv_output_path/invalid_file)\n",
    "        except Exception as e:\n",
    "                logging.warning(f'{e}')\n",
    "\n",
    "    \n",
    "    return {'confirmed': csv_output_path/confirmed_file, \n",
    "            'unconfirmed': csv_output_path/unconfirmed_file, \n",
    "            'invalid': csv_output_path/invalid_file}\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def window_drive_path():\n",
    "    '''launch an interactive window to ask user to specify a google drive shared folder'''\n",
    "    drive_path = sg.Window(constants.app_name,\n",
    "                          [[sg.Text ('Choose the Google Shared Drive and folder that contains student cummulative folders.')],\n",
    "                                     [sg.In(), sg.FolderBrowse()],\n",
    "                                     [sg.Ok(), sg.Cancel()]]).read(close=True)[1][0]\n",
    "    \n",
    "    if drive_path:\n",
    "        drive_path = Path(drive_path)\n",
    "    else: \n",
    "        drive_path = None\n",
    "        logging.info('no drive path selected')\n",
    "        \n",
    "    return drive_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def window_csv_file():\n",
    "    '''launch an interactive window to ask user to specify a student export file'''\n",
    "#     student_export = sg.Window(constants.app_name,\n",
    "#                           [[sg.Text ('Choose a student.export.text file to process')],\n",
    "#                                      [sg.In(), sg.FolderBrowse()],\n",
    "#                                      [sg.Ok(), sg.Cancel()]]).read(close=True)[1][0]\n",
    "    csv_file = sg.popup_get_file('Select a Student Export File to Process')\n",
    "    \n",
    "    if csv_file:\n",
    "        csv_file = Path(csv_file)\n",
    "    else: \n",
    "        csv_file = None\n",
    "        logging.info('no student_export path selected')\n",
    "        \n",
    "    return csv_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_help():\n",
    "    print('this is the help')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_program(interactive=False):\n",
    "    # set the local logger\n",
    "    logger = logging.getLogger(__name__)\n",
    "    logging.info('*'*50+'\\n')\n",
    "    \n",
    "    # base configuration fle\n",
    "    config_file = Path(constants.config_file)\n",
    "    # user config file (~/.config/app_name/app.ini)\n",
    "    user_config_path = Path(constants.user_config_path)\n",
    "    \n",
    "    # if the user configuration file is missing set to True & create later at end\n",
    "    update_user_config = not(user_config_path.exists)\n",
    "    logging.debug(f'user config will be created: {update_user_config}')\n",
    "\n",
    "    # parse command line and config files - \n",
    "    cmd_args_dict = parse_cmdargs()\n",
    "    cfg_files_dict = read_config([constants.config_file, constants.user_config_path])\n",
    "\n",
    "    # merge the command line arguments and the config files; cmd line overwrites files\n",
    "    config = ArgConfigParse.merge_dict(cfg_files_dict, cmd_args_dict)    \n",
    "    \n",
    "    if config['__cmd_line']['version']:\n",
    "        logging.debug('display version and exit')\n",
    "        return do_exit(f'{constants.app_name} version: {constants.version}\\n{constants.contact}\\n{constants.git_repo}', 0)\n",
    "    \n",
    "    # handle missing google shared drive paths\n",
    "    if not config['main']['drive_path']:\n",
    "        if interactive:\n",
    "            print('No Google Shared Drive has been set.')\n",
    "            print('Choose a Google Shared Drive that Contains Student Cumulative (portfolio) folders')\n",
    "            drive_path_interactive = window_drive_path()\n",
    "            if not drive_path_interactive: \n",
    "                return do_exit('Please choose a Google Shared Drive to proceed', 0)\n",
    "            else:\n",
    "                config['main']['drive_path'] = drive_path_interactive\n",
    "                \n",
    "        if not interactive:\n",
    "            return (do_exit(f'Can not run without a Google Shared Drive Configured.\\ntry:\\n{sys.argv[0]} -h for help', 1))\n",
    "    \n",
    "    # adjust logging levels if needed\n",
    "    if config['main']['log_level']:\n",
    "        ll = config['main']['log_level']\n",
    "        if ll in (['DEBUG', 'INFO', 'WARNING', 'ERROR']):\n",
    "            logging.root.setLevel(ll)\n",
    "            handlers = adjust_handler ('*', ll)\n",
    "            logging.debug(f'adjusted log levels: {handlers} to {ll}')\n",
    "        else:\n",
    "            logging.warning(f'unknown or invalid log_level: {ll}')\n",
    "\n",
    "    # load file constants\n",
    "    expected_headers = constants.expected_headers    \n",
    "    student_dirs = constants.student_dirs\n",
    "    \n",
    "    # set local vars\n",
    "    drive_path = Path(config['main']['drive_path'])\n",
    "    \n",
    "    drive_status = check_drive_path(drive_path)\n",
    "    if not drive_status[0]:\n",
    "        return do_exit(drive_status[1], 0)\n",
    "          \n",
    "    # get csv_file and drive path\n",
    "    if interactive:\n",
    "        print('Select a student export file to process')\n",
    "        csv_file = window_csv_file()\n",
    "        if not csv_file:\n",
    "            return do_exit('Can not proceed without a student export file.', 0)\n",
    "    else:\n",
    "        try:\n",
    "            csv_file = Path(config['__cmd_line']['student_export'])\n",
    "        except TypeError:\n",
    "            return do_exit('No student export file specified on command line', 1)\n",
    "        \n",
    "    if not csv_file:\n",
    "        return do_exit('Student export file missing', 1)\n",
    "    \n",
    "    # read the CSV file\n",
    "    try:\n",
    "        print(f'\\nProcessing {csv_file}...')\n",
    "        csv_list = csv_to_list(csv_file)\n",
    "    except (FileNotFoundError, OSError, IOError, TypeError) as e:\n",
    "        logging.error(f'could not read csv file: {csv_file.name}')\n",
    "        logging.error(e)\n",
    "        return do_exit(e, 1)\n",
    "    except csv.Error as e:\n",
    "        logging.error(f'could not process csv file: {csv_file.name}')\n",
    "        logging.error(e)\n",
    "        return do_exit(e, 1)\n",
    "    finally:\n",
    "        print('done processing')\n",
    "   \n",
    "    # map the headers \n",
    "    print(f'checking for appropriate column headers')\n",
    "    header_map, missing_headers = map_headers(csv_list, expected_headers.keys())\n",
    "    \n",
    "    if len(missing_headers) > 0:\n",
    "        return do_exit(f'{csv_file.name} is missing one or more column headers:\\n{missing_headers}\\n\\ncan not proceed with this file', 0)\n",
    "    \n",
    "    # validate rows in the CSV file\n",
    "    print(f'\\nchecking each row for valid data')\n",
    "    valid_rows, invalid_rows = validate_data(csv_list, expected_headers, header_map)\n",
    "    print(f'{len(valid_rows)} student rows were found and will be processed')\n",
    "    print(f'{len(invalid_rows)} improperly formatted student rows were found and will be skipped')\n",
    "    \n",
    "    # insert the header into the invalid_rows for later output\n",
    "    invalid_rows.insert(0, csv_list[0])\n",
    "    \n",
    "    print(f'\\nPreparing to process and create student folders for{len(valid_rows)} students')\n",
    "    print(f'using Google Shared Drive: {drive_path}')\n",
    "    print(f'this could take some time...')\n",
    "    \n",
    "    directories = create_folders(drive_path=drive_path, valid_rows=valid_rows, header_map=header_map)\n",
    "    \n",
    "    \n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "    return do_exit('Done', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sys.argv.append('-v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.argv.append('-s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.argv.append('./data/invalid.student.export.text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sys.argv.pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'drive_path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-b2826d45971b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmain_program\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-27-4605295e2f35>\u001b[0m in \u001b[0;36mmain_program\u001b[0;34m(interactive)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'\\nPreparing to process and create student folders for{len(valid_rows)} students'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'using Google Shared Drive: {drive_path}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'this could take some time...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'drive_path' is not defined"
     ]
    }
   ],
   "source": [
    "f = main_program()\n",
    "f()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_gui = False\n",
    "if len(sys.argv) <= 1:\n",
    "    run_gui = True\n",
    "    \n",
    "if '-f' in sys.argv:\n",
    "    logging.debug('likely running in a jupyter environ')\n",
    "    run_gui = True\n",
    "\n",
    "if run_gui:\n",
    "#     print = sg.Print\n",
    "    def text_fmt(text, *args, **kwargs): return sg.Text(text, *args, **kwargs, font='Courier 15')\n",
    "    layout =[ [text_fmt('Cumulative Portfolio Creator')],\n",
    "      [sg.Text('Create Cumulative Folders on Google Shared Drive', font='Courier 11')],\n",
    "      [sg.Output(size=(80, 50), font='Courier 12')],\n",
    "      [sg.Button('GO'), sg.Button('Help'), sg.Button('EXIT')],\n",
    "            ]\n",
    "\n",
    "    window = sg.Window('Cumulative Portfolio Creator', layout=layout, keep_on_top=False)\n",
    "\n",
    "    while True:\n",
    "        window.finalize()\n",
    "        window.BringToFront()\n",
    "        (event, value) = window.read()\n",
    "\n",
    "\n",
    "\n",
    "        if event == 'EXIT' or event == sg.WIN_CLOSED:\n",
    "            break\n",
    "        if event == 'GO':\n",
    "            ret_val = main_program(run_gui)\n",
    "            ret_val()\n",
    "        if event == 'Help':\n",
    "            print_help()\n",
    "    window.close()\n",
    "    sg.easy_print_close()\n",
    "\n",
    "# run in non-interactive command line mode\n",
    "else:\n",
    "    ret_val = main_program()\n",
    "    ret_val()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "portfolioCreator-alMouNtK",
   "language": "python",
   "name": "portfoliocreator-almountk"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
