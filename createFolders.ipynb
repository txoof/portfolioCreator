{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "%reload_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "%alias nb_convert ~/bin/develtools/nbconvert createFolders.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/aciuffo/bin/develtools/nbconvert, createFolders.ipynb,\n",
      "[NbConvertApp] Converting notebook createFolders.ipynb to python\n"
     ]
    }
   ],
   "source": [
    "%nb_convert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import csv\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import subprocess\n",
    "import time\n",
    "import ArgConfigParse\n",
    "import constants\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)\n",
    "logger.root.setLevel('DEBUG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_to_list(file):\n",
    "    '''read csv file `file` into a list\n",
    "    \n",
    "    Guess the CSV dialect (e.g. tsv, csv, etc.)\n",
    "    \n",
    "    Returns `list`'''\n",
    "    logging.debug(f'reading {file} to list')\n",
    "    csvFile = Path(file).expanduser().absolute()\n",
    "    file_csv = []\n",
    "    # try to figure out the dialect (csv, tsv, etc.)\n",
    "    with open(csvFile, 'r') as file:\n",
    "        dialect = csv.Sniffer().sniff(file.read(1024))\n",
    "        file.seek(0)\n",
    "        reader = csv.reader(file, dialect)\n",
    "        for row in reader:\n",
    "            file_csv.append(row)\n",
    "\n",
    "    return file_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_headers(csv_list, expected_headers=[]):\n",
    "    '''map row 0 of a csv as formatted as a list to a dictionary of expected header values'''\n",
    "    missing_headers = []\n",
    "    header_map = {}\n",
    "    \n",
    "    csvHeader = csv_list[0]\n",
    "    logger.debug('mapping headers')\n",
    "    logger.debug('checking for missing headers')\n",
    "    for each in expected_headers:\n",
    "        if each not in csvHeader:\n",
    "            missing_headers.append(each)\n",
    "            \n",
    "    if len(missing_headers) > 0:\n",
    "        logging.warning(f'missing expected headers: {missing_headers}')\n",
    "    for index, value in enumerate(csvHeader):\n",
    "        if value in expected_headers:\n",
    "            header_map[value] = index\n",
    "        \n",
    "    logging.debug('completed mapping')\n",
    "    return(header_map, missing_headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_exit(e='unknown error in unknown module: BSoD!', exit_status=0, testing=False):\n",
    "    logging.info(f'exited before completion with exit code {exit_status}')\n",
    "    print('\\n'*4)\n",
    "    if exit_status > 0:\n",
    "        print('program exited due to errors')\n",
    "    print(e)\n",
    "    if not testing:\n",
    "        sys.exit(exit_status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class gd_path():\n",
    "    def __init__(self, path=None):\n",
    "        '''google drive path class\n",
    "        \n",
    "        Attributes:\n",
    "            path(`str`): path to google drive drive object'''\n",
    "        self.confirmed = False\n",
    "        self.path = path\n",
    "        self._file_base = 'https://drive.google.com/file/d/'\n",
    "        self._dir_base = 'https://drive.google.com/drive/folders/'\n",
    "        self.is_file = False   \n",
    "    \n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f'gd_path({self.path})'\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f'{self.path}'\n",
    "    \n",
    "    @property\n",
    "    def path(self):\n",
    "        return self._path\n",
    "    \n",
    "    @path.setter\n",
    "    def path(self, path):\n",
    "        '''full path to object\n",
    "        \n",
    "        Args:\n",
    "            path(`str` or `Path`): /path/to/object\n",
    "            \n",
    "        Sets Attributes:\n",
    "            self.path: path to object\n",
    "            self.root: same as path for directories, parent directory for files\n",
    "            self.is_file: true for files and file-like objects, false for directories'''\n",
    "        if not path:\n",
    "            self._path = None\n",
    "        else:\n",
    "            self._path = Path(path)\n",
    "            if self._path.is_dir() and self._path.exists():\n",
    "                self.root = self._path\n",
    "                self.is_file = False\n",
    "            if self.path.is_file() and self._path.exists():\n",
    "                self.root = self._path.parent\n",
    "                self.is_file = True\n",
    "            \n",
    "            if not self._path.exists():\n",
    "                self.is_file = False\n",
    "                self.root = self._path.parent\n",
    "\n",
    "    @property\n",
    "    def webview_link(self):\n",
    "        '''full webview link to object in google drive'''\n",
    "        self._webview_link = None\n",
    "        try:\n",
    "            item_id = self.get_xattr('user.drive.id')\n",
    "        except FileNotFoundError as e:\n",
    "            logging.debug(f'{e}')\n",
    "            return None\n",
    "        except ChildProcessError as e:\n",
    "            logging.debug(f'{e}')\n",
    "            return None\n",
    "\n",
    "        if len(item_id) < 1:\n",
    "            return None\n",
    "        else:\n",
    "            item_id = item_id[0]\n",
    "        \n",
    "        \n",
    "        if not self.is_file:\n",
    "            self._webview_link = f'{self._dir_base}{item_id}'\n",
    "        if self.is_file:\n",
    "            self._webview_link = f'{self._file_base}{item_id}'\n",
    "        return self._webview_link\n",
    "            \n",
    "    def check_parent(self, expected):\n",
    "        '''checks if the parent matches the expected parent'''\n",
    "        if self.root.parents[0].name == expected:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "        \n",
    "    def get_xattr(self, attribute, file=None):\n",
    "        '''get the extended attributes of a file or directory\n",
    "        Args:\n",
    "            file(`str` or Path): path to file\n",
    "            attribute('`str`'): attribute key to access\n",
    "\n",
    "        Returns:\n",
    "            `list` - attribute or key: attribute pairs\n",
    "\n",
    "        Raises:\n",
    "            FileNotFoundError - file or directory does not exist\n",
    "            ChildProcessError - xattr utility exits with non-zero code \n",
    "                This is common for files that have no extended attributes or do not\n",
    "                have the requested attribute'''\n",
    "        if not file:\n",
    "            file = self.path\n",
    "        else:\n",
    "            file = Path(file).absolute()\n",
    "            \n",
    "        attributes = []\n",
    "        if not file.exists():\n",
    "            raise FileNotFoundError(file)\n",
    "\n",
    "        p = subprocess.Popen(f'xattr -p  {attribute} \"{file.resolve()}\"', shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT)\n",
    "        for line in p.stdout.readlines():\n",
    "            attributes.append(line.decode(\"utf-8\").strip())\n",
    "    #         attributes = attributes + line.decode(\"utf-8\").strip()\n",
    "        retval = p.wait()\n",
    "        if retval != 0:\n",
    "            raise ChildProcessError(f'xattr exited with value: {retval}')\n",
    "        return attributes     \n",
    "\n",
    "    @property\n",
    "    def file_id(self, path=None):\n",
    "        '''unique file id for each object (directories or file)\n",
    "        \n",
    "        Args:\n",
    "            path(`str` or `Path`): path to object; defaults to self.path\n",
    "        \n",
    "        Returns:\n",
    "            `list` of `str` containing the file id'''\n",
    "        if not path:\n",
    "            path = self.path\n",
    "        try:\n",
    "            file_id = self.get_xattr('user.drive.id', path)\n",
    "        except FileNotFoundError as e:\n",
    "            logging.info(f'{path} does not appear to exist; cannot get attributes')\n",
    "            file_id = None\n",
    "        return file_id\n",
    "    \n",
    "    def confirm(self, path=None):\n",
    "        '''confirm that a created object has been sent over file stream\n",
    "        \n",
    "        Args:\n",
    "            path(`str` or `Path`): path to object; default is self.path\n",
    "        \n",
    "        Returns:\n",
    "            `list` of `str` containing the file id\n",
    "            \n",
    "        Attributes Set:\n",
    "            self.confirmed: True when object has been sent'''\n",
    "        \n",
    "        if not path:\n",
    "            path = self.path\n",
    "        file_id = self.file_id\n",
    "        \n",
    "        if file_id:\n",
    "            if 'local-' in file_id[0]:\n",
    "                self.confirmed = False\n",
    "                file_id = None\n",
    "            else:\n",
    "                self.confirmed = True\n",
    "        return file_id\n",
    "    \n",
    "    def mkdir(self, path=None, parents=False, exist_ok=False, kwargs={}):\n",
    "        '''create a directory using pathlib.Path().mkdir()\n",
    "        \n",
    "        Args:\n",
    "            path(`str` or `Path`): path to create\n",
    "            parents(`bool`): create parent directories - default false\n",
    "            exists_ok(`bool`): do not raise error if directory exists\n",
    "            kwargs: kwargs for pathlib.Path().mkdir()\n",
    "            \n",
    "        Returns:\n",
    "            file_id(`list`)'''\n",
    "        if not path:\n",
    "            path = self.path\n",
    "            logging.debug(f'using self.path: {path}')\n",
    "        else:\n",
    "            logging.debug(f'using supplied path: {path}')\n",
    "            \n",
    "        if path.is_file():\n",
    "            raise TypeError(f'{path} is a file')\n",
    "            \n",
    "        path = Path(path)\n",
    "            \n",
    "        path.mkdir(parents=parents, exist_ok=exist_ok, **kwargs)\n",
    "        if self.confirm(path):\n",
    "            file_id = self.get_xattr('user.drive.id', path)\n",
    "        return self.file_id\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class student_path(gd_path):\n",
    "    def __init__(self, path=None, class_of=None, id_number=None, name=None):\n",
    "        '''student directory in google drive; child class of gd_path:\n",
    "        \n",
    "        Args:\n",
    "        \n",
    "        Properties:\n",
    "            class_of(`str`): \"ClassOf-YYYY\" string representation of projected graduation year\n",
    "            name(`str`): \"Last, First\" string representation of student name\n",
    "            id_number(`int`): student id number\n",
    "            matches(`dict`):  name and webview link of directories that contain \"id_number\"\n",
    "            path_parts(`dict`): path compontents stored as dictionary keys'''\n",
    "        \n",
    "        super(student_path, self).__init__(path=path)\n",
    "        self.matches = {}\n",
    "        self.path_parts = {'ClassOf': None, 'id_number': None, 'name': None}\n",
    "        self.class_of = class_of\n",
    "        self.name = name\n",
    "        self.id_number = id_number\n",
    "    \n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f'student_path({self.student_dir_name})'\n",
    "        \n",
    "    def __str__(self):\n",
    "        return f'{self.student_dir_name}'\n",
    "    \n",
    "    def get_xattr(self, attribute, file=None):\n",
    "        if not file:\n",
    "            file = self.student_dir_name\n",
    "        return super().get_xattr(attribute, file)\n",
    "    \n",
    "    @property\n",
    "    def class_of(self):\n",
    "        return self._class_of\n",
    "    \n",
    "    @class_of.setter\n",
    "    def class_of(self, class_of):\n",
    "        '''string representation of projected graduation date in format: \"ClassOf-YYYY\"\n",
    "        \n",
    "        Properties Set:\n",
    "            path_parts(`dict`): dictionary of component parts of path'''\n",
    "        if not class_of:\n",
    "            self._class_of = None\n",
    "        else:\n",
    "            # attempt to coerce strings from cSV file into type int\n",
    "            class_of = int(class_of)\n",
    "            if not isinstance(class_of, int):\n",
    "                raise TypeError('class_of must be of type `int`')\n",
    "        self.path_parts['ClassOf'] = f'ClassOf-{class_of}'\n",
    "        self._class_of = class_of\n",
    "        \n",
    "    @property\n",
    "    def name(self):\n",
    "        return self._name\n",
    "    \n",
    "    @name.setter\n",
    "    def name(self, name):\n",
    "        '''string representation of \"Last, First\" names\n",
    "        \n",
    "        Properties Set:\n",
    "            path_parts(`dict`): dictionary of component parts of path'''\n",
    "        if not name:\n",
    "            self._name = None\n",
    "        else:\n",
    "            if not isinstance (name, str):\n",
    "                raise TypeError('name must be of type `str`')\n",
    "        self.path_parts['name'] = name\n",
    "        self._name = name\n",
    "        \n",
    "    @property\n",
    "    def id_number(self):\n",
    "        return self._id_number\n",
    "    \n",
    "    @id_number.setter\n",
    "    def id_number(self, number):\n",
    "        '''integer of student id number\n",
    "        \n",
    "        Properties Set:\n",
    "            path_parts(`dict`): dictionary of component parts of path'''\n",
    "        if not number:\n",
    "            self._id_number = None\n",
    "        else:\n",
    "            # try to coerce number into type int\n",
    "            number = int(number)\n",
    "            if not isinstance (number, int):\n",
    "                raise TypeError('id_number must be of type `int`')\n",
    "        self.path_parts['id_number'] = number\n",
    "        self._id_number = number\n",
    "\n",
    "    @property\n",
    "    def student_dir_name(self):\n",
    "        '''full absolute path to student directory in format:\n",
    "            ClassOf-YYYY/Last, First - NNNNNNN'''\n",
    "        d = f\"/{self.path_parts['ClassOf']}/{self.path_parts['name']} - {self.path_parts['id_number']}\"\n",
    "        if self.path:\n",
    "            # not sure why this is needed, but any joining of self.root/Path(d) fails\n",
    "            d = f'{str(self.path)}/{d}'\n",
    "        return Path(d)\n",
    "    \n",
    "    # method for checking for similarly named student folders in this ClassOf folder\n",
    "    def check_similar(self):\n",
    "        '''check for similarly named directories based on student id number \n",
    "        within the path/ClassOf/ directory\n",
    "        \n",
    "        Properties Set:\n",
    "            self.matches(`dict`): dictionary of similar directories\n",
    "        Returns:\n",
    "            `bool`: True if matching directories found'''\n",
    "        similar = False\n",
    "        matches = {}\n",
    "        for i in self.student_dir_name.parent.glob(f\"*{self.path_parts['id_number']}*\"):\n",
    "            match_id = self.get_xattr('user.drive.id', self.student_dir_name.parent/i)\n",
    "            if i.absolute().is_dir():\n",
    "                url = '/'.join((self._dir_base, match_id[0]))\n",
    "            else:\n",
    "                url = '/'.join((self._file_base, match_id[0]))\n",
    "            matches[str(i)] = url\n",
    "        self.matches = matches\n",
    "        if matches:\n",
    "            similar = True\n",
    "        return similar\n",
    "\n",
    "    def mkdir(self, path=None, exist_ok=False, parents=True, kwargs={}):\n",
    "        '''make a google drive directory using pathlib.Path().mkdir()\n",
    "        \n",
    "        Args:\n",
    "            path(`str` or `Path`): defaults to self.student_dir_name\n",
    "            exist_ok(`bool`): True - do not raise error if directory exists\n",
    "            parents(`bool`): True - create parents if they do not exist\n",
    "            kwargs({}): pathlib.Path() kwargs\n",
    "            \n",
    "        Returns:\n",
    "            list[str]: google drive object ID string'''\n",
    "        if not path:\n",
    "            path = self.student_dir_name\n",
    "        logging.debug(f'calling super().mkdir(path={path})')\n",
    "        val = super().mkdir(path=path, exist_ok=exist_ok, parents=parents, **kwargs)\n",
    "        return val\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_data(csv_list, expected_headers, header_map):\n",
    "    '''validate list items for proper data types\n",
    "         naievely attempts to coerce strings from CSV into expected_header types\n",
    "         returns a tuple of list of rows that were successfully coerced and those\n",
    "         that could not be coerced\n",
    "    \n",
    "    Args:\n",
    "        csv_list(`list` of `list`): csv as a nested list [['h1', 'h2'], ['item', 'item2']]\n",
    "        expected_headers(`dict`): {'literal_header': type} {'ClassOf':, int, 'Name', str}\n",
    "        header_map(`dict`): map of list index for each header {'h1': 0, 'h2': 5, 'hN': i}\n",
    "        \n",
    "    Returns:\n",
    "        (`tuple` of `list`): (valid_rows, invalid_rows)\n",
    "    '''\n",
    "    valid = []\n",
    "    invalid = []\n",
    "\n",
    "    for row in csv_list[1:]:\n",
    "        good_row = True\n",
    "        for k in expected_headers.keys():\n",
    "            # test for coercable types\n",
    "            try:\n",
    "                test = expected_headers[k](row[header_map[k]])\n",
    "            except ValueError:\n",
    "#                 do_exit(f'Bad student.export: {k} contained {row[header_map[k]]}\\ncannot continue. Please try running the export again.')\n",
    "                logging.warning(f'{row}')\n",
    "                logging.warning(f'Bad student.export: column \"{k}\" contained \"{row[header_map[k]]}\"--this should be {(expected_headers[k])}')\n",
    "                invalid.append(row)\n",
    "                good_row = False\n",
    "                break\n",
    "        if  good_row:\n",
    "            valid.append(row)\n",
    "        \n",
    "    return valid, invalid\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    config_file = constants.config_file\n",
    "    user_config_path = constants.user_config_path\n",
    "\n",
    "    # gather command line arguments\n",
    "    args = ArgConfigParse.CmdArgs()\n",
    "\n",
    "    args.add_argument('-s', '--student_export', ignore_none=False, metavar='/path/to/student.export.csv', \n",
    "                      type=str, dest='student_export', help='Export from PowerSchool containing: LastFirst, ClassOf, Student_Number')\n",
    "\n",
    "    args.add_argument('-g', '--google_drive', ignore_none=True, metavar='/Volumes/GoogleDrive/Shared drives/ASH Cum Folders/folder/',\n",
    "                      type=str, dest='main__drive_path', help='Full path to Google Drive Shared Drive containing cumulative files')\n",
    "\n",
    "    args.add_argument('-l', '--log_level', ignore_none=True, metavar='ERROR, WARNING, INFO, DEBUG', \n",
    "                      type=str, dest='main__log_level', help='Logging level -- Default: WARNING')\n",
    "\n",
    "    args.parse_args()\n",
    "    \n",
    "    \n",
    "    # create a parser for the config files\n",
    "    parser = ArgConfigParse.ConfigFile([config_file, user_config_path])\n",
    "    parser.parse_config()\n",
    "\n",
    "    \n",
    "    config = ArgConfigParse.merge_dict(parser.config_dict, args.nested_opts_dict)\n",
    "    \n",
    "    \n",
    "    # get csv_file and drive_path from the command line\n",
    "    try:\n",
    "        csv_file = Path(config['__cmd_line']['student_export'])\n",
    "    except TypeError:\n",
    "        logging.info('No student export file specified on command line')\n",
    "        csv_file = None\n",
    "\n",
    "    drive_path = Path(config['main']['drive_path'])\n",
    "    if not drive_path:\n",
    "        logging.info('No google drive path specified on command line')\n",
    "    \n",
    "\n",
    "    # load constants\n",
    "    sentry_file = constants.sentry_file    \n",
    "    \n",
    "    expected_headers = constants.expected_headers\n",
    "    \n",
    "    # try to confirm created files N times before giving up\n",
    "    confirm_retry = constants.confirm_retry\n",
    "    \n",
    "    #  wait N seconds for first try, N*retry for each subsiquent retry\n",
    "    base_wait = constants.base_wait\n",
    "    \n",
    "    student_dirs = constants.student_dirs\n",
    "    \n",
    "    logging.debug('starting up')\n",
    "    \n",
    "    # check drive path is on a shared drive \n",
    "    google_drive = gd_path(drive_path)\n",
    "    try:\n",
    "        google_drive.get_xattr('user.drive.id')\n",
    "    except ChildProcessError as e:\n",
    "        do_exit(f'The specified Google Drive \"{drive_path}\" is not a Shared Drive', 1)\n",
    "    except FileNotFoundError as e:\n",
    "        do_exit(f'The specified Google Shared Drive {drive_path}\" does not exist', 1)\n",
    "    \n",
    "    # check if sentry file exists\n",
    "    sentry_file_path = drive_path/Path(sentry_file)\n",
    "    if not sentry_file_path.is_file():\n",
    "        m = f'''The chosen google shared drive \"{drive_path}\"\n",
    "does not appear to be a Cumulative Student Folder. \n",
    "\n",
    "The file: \"{sentry_file}\" is missing. \n",
    "If you are sure {drive_path} is correct, \n",
    "please contact IT Support and askfor help. \n",
    "\n",
    "Please screenshot or copy this entire text below and provide it to IT Support.\n",
    "\n",
    "###############################################################################\n",
    "Run the command below from the terminal of the user that submitted this ticket.\n",
    "This command will create the necessary files for this script. \n",
    "\n",
    "Confirm that {drive_path} is the correct\n",
    "Google Shared Drive for Cumulative Student folders BEFORE proceeding.\n",
    "     $ touch {drive_path}/{sentry_file}'''\n",
    "        logging.error(m)\n",
    "        do_exit(m, 1)\n",
    " \n",
    "    # read CSV into a list\n",
    "    if not csv_file:\n",
    "        do_exit('No CSV file specified. Exiting.', 0)\n",
    "    try:\n",
    "        csv_list = csv_to_list(csv_file)\n",
    "    except (FileNotFoundError, OSError, IOError) as e:\n",
    "        logging.error(f'could not read csv file: {csv_file}')\n",
    "        logging.error(f'{e}')\n",
    "        do_exit(e, 1)\n",
    "    \n",
    "    # map the expecdted headers to the appropriate columns\n",
    "    header_map, missing_headers = map_headers(csv_list, expected_headers.keys())\n",
    "    \n",
    "    # error out if there are any missing headers\n",
    "    if len(missing_headers) > 0:\n",
    "        do_exit(f'{csv_file.name} is missing one or more headers:\\n\\t{missing_headers}\\nprogram cannot continue', 1)\n",
    "    \n",
    "    # validate the csv list\n",
    "    valid_rows, invalid_rows = validate_data(csv_list, expected_headers, header_map)\n",
    "\n",
    "    # dictionary to record created directories\n",
    "    directories = {'created': [], 'skipped': [], 'invalid': invalid_rows, \n",
    "                   'confirmed': [], 'failed': []}\n",
    "    for row in valid_rows:\n",
    "        name = row[header_map['LastFirst']]\n",
    "        class_of = row[header_map['ClassOf']]\n",
    "        id_number = row[header_map['Student_Number']]\n",
    "        \n",
    "        s_path = student_path(path=drive_path,\n",
    "                              name=name, \n",
    "                              class_of=class_of, \n",
    "                              id_number=id_number)\n",
    "        \n",
    "        # check if there already exists a directory with the student number\n",
    "        if s_path.check_similar():\n",
    "            # flag those that have multiple entries\n",
    "            if len(s_path.matches) > 1:\n",
    "                logging.warning(f'multiple directories exist in {class_of} for student number {id_number}')\n",
    "                directories['skipped'].append((s_path, 'multiple'))\n",
    "            # flag those that already exist for auditing purposes\n",
    "            else:\n",
    "                logging.info(f'skipped {class_of}/{name} - {id_number}: folder exists')\n",
    "                directories['skipped'].append((s_path, 'exists'))\n",
    "\n",
    "                \n",
    "        else:\n",
    "            # create the directory and try to handle errors as needed\n",
    "            try:\n",
    "                s_path.mkdir(parents=True)\n",
    "            except FileExistsError as e:\n",
    "                logging.error(f'{s_path.student_dir_name} exists')\n",
    "                directories['skipped'].append((s_path, 'exists'))\n",
    "            except OSError as e:\n",
    "                logging.error(f'Could not create {s_path.student_dir_name}: {e}')\n",
    "                directories['skipped'].append((s_path, 'failed'))\n",
    "            else:\n",
    "                directories['created'].append(s_path)\n",
    "\n",
    "# inject a bad entry to test checks at end\n",
    "#     directories['created'].append(student_path(path='/Volumes/GoogleDrive/Shared drives/IT Blabla I/spam_eggs_spam',\n",
    "#                                                name='Eggs, Green', class_of=1000, id_number=123456))\n",
    "    \n",
    "    \n",
    "    # double check that drectories were created and properly synced to google drive\n",
    "    for i in range(0, confirm_retry):\n",
    "        if len(directories['created']) > 0:\n",
    "            wait = i * base_wait\n",
    "        dirs_to_check = directories['created']\n",
    "        for each in dirs_to_check:\n",
    "            logging.info(f'checking: {each}')\n",
    "            if each.confirm():\n",
    "                logging.debug(f'confirmed: {each}')\n",
    "                directories['confirmed'].append(each)\n",
    "                directories['created'].remove(each)\n",
    "            \n",
    "            # loop over the created directories N times with a longer delay each time\n",
    "            # check that everything is confirmed uploaded; if it is not after Nth time, \n",
    "            # log as 'failed'\n",
    "        if len(directories['created']) > 0:\n",
    "            logging.info(f'sleeping for {wait} seconds and checking dirs again')\n",
    "            time.sleep(wait)\n",
    "        else:\n",
    "            logging.info('all created directories confirmed')\n",
    "            break\n",
    "\n",
    "    \n",
    "    if len(directories['created']) > 0:\n",
    "        directories['failed'] = directories['created']\n",
    "        directories['created'] = []\n",
    "#         dirs_to_check = directories['created']\n",
    "#         # migrate the created to the failed\n",
    "#         for each in dirs_to_check:\n",
    "#             directories['failed'].append(directories['created'].pop())\n",
    "    \n",
    "    # add better reporting on total attempted, created, skipped, failed, confirmed\n",
    "    total = 0\n",
    "    for each in directories:\n",
    "        total = total + len(each)\n",
    "    \n",
    "    # run over skipped and report those that have multiple directories and the path\n",
    "    # user should deal with these.\n",
    "    skipped = len(directories['skipped'])\n",
    "    failed = len(directories['failed'])\n",
    "    confirmed = len(directories['confirmed'])\n",
    "    invalid = len(directories['invalid'])\n",
    "        \n",
    "    return directories\n",
    "    \n",
    "    # cleanup\n",
    "    # handle invalid_rows -- notify user of issues\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:root:options: Namespace(main__drive_path=None, main__log_level=None, student_export=None)\n",
      "DEBUG:root:ignoring key: main__drive_path\n",
      "DEBUG:root:ignoring key: main__log_level\n",
      "INFO:root:ignoring unknown options: ['-f', '/Users/aciuffo/Library/Jupyter/runtime/kernel-7d2d1147-52b6-4a52-a6f1-7ec5d903a639.json']\n",
      "INFO:root:processing config files: [PosixPath('/Users/aciuffo/Documents/src/portfolioCreator/createFolders.ini')]\n",
      "WARNING:root:config files not found: [PosixPath('/Users/aciuffo/com.txoof.createFolders/createFolders.ini')]\n",
      "INFO:root:No student export file specified on command line\n",
      "DEBUG:root:starting up\n",
      "INFO:root:exited before completion with exit code 1\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "INFO:root:\n",
      "Unfortunately, your original traceback can not be constructed.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "program exited due to errors\n",
      "The specified Google Drive \".\" is not a Shared Drive\n",
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-17-0eddbf39fc25>\", line 65, in main\n",
      "    google_drive.get_xattr('user.drive.id')\n",
      "  File \"<ipython-input-9-3c2faa466185>\", line 111, in get_xattr\n",
      "    raise ChildProcessError(f'xattr exited with value: {retval}')\n",
      "ChildProcessError: xattr exited with value: 1\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/aciuffo/.local/share/virtualenvs/portfolioCreator-ahiuVo4K/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3331, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-18-e17704727001>\", line 1, in <module>\n",
      "    f = main()\n",
      "  File \"<ipython-input-17-0eddbf39fc25>\", line 67, in main\n",
      "    do_exit(f'The specified Google Drive \"{drive_path}\" is not a Shared Drive', 1)\n",
      "  File \"<ipython-input-7-1979fc9e640e>\", line 6, in do_exit\n",
      "    sys.exit(exit_status)\n",
      "SystemExit: 1\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/aciuffo/.local/share/virtualenvs/portfolioCreator-ahiuVo4K/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1148, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/Users/aciuffo/.local/share/virtualenvs/portfolioCreator-ahiuVo4K/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 316, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/Users/aciuffo/.local/share/virtualenvs/portfolioCreator-ahiuVo4K/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 350, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/inspect.py\", line 1503, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "AttributeError: 'tuple' object has no attribute 'tb_frame'\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aciuffo/.local/share/virtualenvs/portfolioCreator-ahiuVo4K/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3339: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "f = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sys.argv.append('-s')\n",
    "# sys.argv.append('./student.export.csv.text')\n",
    "# # f = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sys.argv.append('-g')\n",
    "# sys.argv.append('/Volumes/GoogleDrive/Shared drives/IT Blabla I/Student Cumulative Folders (AKA Student Portfolios)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "portfolioCreator-ahiuVo4K",
   "language": "python",
   "name": "portfoliocreator-ahiuvo4k"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
