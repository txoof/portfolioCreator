{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "%reload_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "%alias nb_convert ~/bin/develtools/nbconvert createFolders.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/aaronciuffo/bin/develtools/nbconvert, createFolders.ipynb,\n",
      "[NbConvertApp] Converting notebook createFolders.ipynb to python\n"
     ]
    }
   ],
   "source": [
    "%nb_convert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import constants\n",
    "# import logging first to prevent any sub modules from creating the root logger\n",
    "import logging\n",
    "from logging import handlers\n",
    "from logging import config\n",
    "logging.config.fileConfig(constants.logging_config, defaults={'logfile': constants.log_file})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import subprocess\n",
    "import time\n",
    "import ArgConfigParse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_to_list(file):\n",
    "    '''read csv file `file` into a list\n",
    "    \n",
    "    Guess the CSV dialect (e.g. tsv, csv, etc.)\n",
    "    \n",
    "    Returns `list`'''\n",
    "    logging.debug(f'reading {file} to list')\n",
    "    csvFile = Path(file).expanduser().absolute()\n",
    "    file_csv = []\n",
    "    # try to figure out the dialect (csv, tsv, etc.)\n",
    "    with open(csvFile, 'r') as file:\n",
    "        dialect = csv.Sniffer().sniff(file.read(1024))\n",
    "        file.seek(0)\n",
    "        reader = csv.reader(file, dialect)\n",
    "        for row in reader:\n",
    "            file_csv.append(row)\n",
    "\n",
    "    return file_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_headers(csv_list, expected_headers=[]):\n",
    "    '''map row 0 of a csv as formatted as a list to a dictionary of expected header values'''\n",
    "    missing_headers = []\n",
    "    header_map = {}\n",
    "    \n",
    "    csvHeader = csv_list[0]\n",
    "    logging.debug('mapping headers')\n",
    "    logging.debug('checking for missing headers')\n",
    "    for each in expected_headers:\n",
    "        if each not in csvHeader:\n",
    "            missing_headers.append(each)\n",
    "            \n",
    "    if len(missing_headers) > 0:\n",
    "        logging.warning(f'missing expected headers: {missing_headers}')\n",
    "    for index, value in enumerate(csvHeader):\n",
    "        if value in expected_headers:\n",
    "            header_map[value] = index\n",
    "        \n",
    "    logging.debug('completed mapping')\n",
    "    return(header_map, missing_headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_exit(e='unknown error in unknown module: BSoD!', exit_status=0, testing=False):\n",
    "\n",
    "        \n",
    "    print('\\n'*4)\n",
    "    if exit_status > 0:\n",
    "        logging.warning(f'exited before completion with exit code {exit_status}')\n",
    "        logging.warning(e)  \n",
    "    elif exit_status > 1:\n",
    "        logging.error(f'fatal error:\\n{e}')\n",
    "    print(e)\n",
    "    sys.exit(exit_status)\n",
    "#     if not testing:\n",
    "#         try:\n",
    "#             sys.exit(exit_status)\n",
    "#         except SystemExit:\n",
    "#             pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class gd_path():\n",
    "    def __init__(self, path=None):\n",
    "        '''google drive path class\n",
    "        \n",
    "        Attributes:\n",
    "            path(`str`): path to google drive drive object'''\n",
    "        self.confirmed = False\n",
    "        self.path = path\n",
    "        self._file_base = 'https://drive.google.com/file/d/'\n",
    "        self._dir_base = 'https://drive.google.com/drive/folders/'\n",
    "        self.is_file = False   \n",
    "    \n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f'gd_path({self.path})'\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f'{self.path}'\n",
    "    \n",
    "    @property\n",
    "    def path(self):\n",
    "        return self._path\n",
    "    \n",
    "    @path.setter\n",
    "    def path(self, path):\n",
    "        '''full path to object\n",
    "        \n",
    "        Args:\n",
    "            path(`str` or `Path`): /path/to/object\n",
    "            \n",
    "        Sets Attributes:\n",
    "            self.path: path to object\n",
    "            self.root: same as path for directories, parent directory for files\n",
    "            self.is_file: true for files and file-like objects, false for directories'''\n",
    "        if not path:\n",
    "            self._path = None\n",
    "        else:\n",
    "            self._path = Path(path)\n",
    "            if self._path.is_dir() and self._path.exists():\n",
    "                self.root = self._path\n",
    "                self.is_file = False\n",
    "            if self.path.is_file() and self._path.exists():\n",
    "                self.root = self._path.parent\n",
    "                self.is_file = True\n",
    "            \n",
    "            if not self._path.exists():\n",
    "                self.is_file = False\n",
    "                self.root = self._path.parent\n",
    "\n",
    "    @property\n",
    "    def webview_link(self):\n",
    "        '''full webview link to object in google drive'''\n",
    "        self._webview_link = None\n",
    "        try:\n",
    "            item_id = self.get_xattr('user.drive.id')\n",
    "        except FileNotFoundError as e:\n",
    "            logging.debug(f'{e}')\n",
    "            return None\n",
    "        except ChildProcessError as e:\n",
    "            logging.debug(f'{e}')\n",
    "            return None\n",
    "\n",
    "        if len(item_id) < 1:\n",
    "            return None\n",
    "        else:\n",
    "            item_id = item_id[0]\n",
    "        \n",
    "        \n",
    "        if not self.is_file:\n",
    "            self._webview_link = f'{self._dir_base}{item_id}'\n",
    "        if self.is_file:\n",
    "            self._webview_link = f'{self._file_base}{item_id}'\n",
    "        return self._webview_link\n",
    "            \n",
    "    def check_parent(self, expected):\n",
    "        '''checks if the parent matches the expected parent'''\n",
    "        if self.root.parents[0].name == expected:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "        \n",
    "    def get_xattr(self, attribute, file=None):\n",
    "        '''get the extended attributes of a file or directory\n",
    "        Args:\n",
    "            file(`str` or Path): path to file\n",
    "            attribute('`str`'): attribute key to access\n",
    "\n",
    "        Returns:\n",
    "            `list` - attribute or key: attribute pairs\n",
    "\n",
    "        Raises:\n",
    "            FileNotFoundError - file or directory does not exist\n",
    "            ChildProcessError - xattr utility exits with non-zero code \n",
    "                This is common for files that have no extended attributes or do not\n",
    "                have the requested attribute'''\n",
    "        if not file:\n",
    "            file = self.path\n",
    "        else:\n",
    "            file = Path(file).absolute()\n",
    "            \n",
    "        attributes = []\n",
    "        if not file.exists():\n",
    "            raise FileNotFoundError(file)\n",
    "\n",
    "        p = subprocess.Popen(f'xattr -p  {attribute} \"{file.resolve()}\"', shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT)\n",
    "        for line in p.stdout.readlines():\n",
    "            attributes.append(line.decode(\"utf-8\").strip())\n",
    "    #         attributes = attributes + line.decode(\"utf-8\").strip()\n",
    "        retval = p.wait()\n",
    "        if retval != 0:\n",
    "            raise ChildProcessError(f'xattr exited with value: {retval}')\n",
    "        return attributes     \n",
    "\n",
    "    @property\n",
    "    def file_id(self, path=None):\n",
    "        '''unique file id for each object (directories or file)\n",
    "        \n",
    "        Args:\n",
    "            path(`str` or `Path`): path to object; defaults to self.path\n",
    "        \n",
    "        Returns:\n",
    "            `list` of `str` containing the file id'''\n",
    "        if not path:\n",
    "            path = self.path\n",
    "        try:\n",
    "            file_id = self.get_xattr('user.drive.id', path)\n",
    "        except FileNotFoundError as e:\n",
    "            logging.info(f'\\'{path}\\' does not appear to exist; cannot get attributes')\n",
    "            file_id = None\n",
    "        return file_id\n",
    "    \n",
    "    def confirm(self, path=None):\n",
    "        '''confirm that a created object has been sent over file stream\n",
    "        \n",
    "        Args:\n",
    "            path(`str` or `Path`): path to object; default is self.path\n",
    "        \n",
    "        Returns:\n",
    "            `list` of `str` containing the file id\n",
    "            \n",
    "        Attributes Set:\n",
    "            self.confirmed: True when object has been sent'''\n",
    "        \n",
    "        if not path:\n",
    "            path = self.path\n",
    "        file_id = self.file_id\n",
    "        \n",
    "        if file_id:\n",
    "            if 'local-' in file_id[0]:\n",
    "                self.confirmed = False\n",
    "                file_id = None\n",
    "            else:\n",
    "                self.confirmed = True\n",
    "        return file_id\n",
    "    \n",
    "    def mkdir(self, path=None, parents=False, exist_ok=False, kwargs={}):\n",
    "        '''create a directory using pathlib.Path().mkdir()\n",
    "        \n",
    "        Args:\n",
    "            path(`str` or `Path`): path to create\n",
    "            parents(`bool`): create parent directories - default false\n",
    "            exists_ok(`bool`): do not raise error if directory exists\n",
    "            kwargs: kwargs for pathlib.Path().mkdir()\n",
    "            \n",
    "        Returns:\n",
    "            file_id(`list`)'''\n",
    "        if not path:\n",
    "            path = self.path\n",
    "            logging.debug(f'using self.path: {path}')\n",
    "        else:\n",
    "            logging.debug(f'using supplied path: {path}')\n",
    "            \n",
    "        if path.is_file():\n",
    "            raise TypeError(f'{path} is a file')\n",
    "            \n",
    "        path = Path(path)\n",
    "            \n",
    "        path.mkdir(parents=parents, exist_ok=exist_ok, **kwargs)\n",
    "        if self.confirm(path):\n",
    "            file_id = self.get_xattr('user.drive.id', path)\n",
    "        return self.file_id\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class student_path(gd_path):\n",
    "    def __init__(self, path=None, class_of=None, id_number=None, name=None):\n",
    "        '''student directory in google drive; child class of gd_path:\n",
    "        \n",
    "        Args:\n",
    "        \n",
    "        Properties:\n",
    "            class_of(`str`): \"ClassOf-YYYY\" string representation of projected graduation year\n",
    "            name(`str`): \"Last, First\" string representation of student name\n",
    "            id_number(`int`): student id number\n",
    "            matches(`dict`):  name and webview link of directories that contain \"id_number\"\n",
    "            path_parts(`dict`): path compontents stored as dictionary keys'''\n",
    "        \n",
    "        super(student_path, self).__init__(path=path)\n",
    "        self.matches = {}\n",
    "        self.path_parts = {'ClassOf': None, 'id_number': None, 'name': None}\n",
    "        self.class_of = class_of\n",
    "        self.name = name\n",
    "        self.id_number = id_number\n",
    "    \n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f'student_path({self.student_dir_name})'\n",
    "        \n",
    "    def __str__(self):\n",
    "        return f'{self.student_dir_name}'\n",
    "    \n",
    "    def get_xattr(self, attribute, file=None):\n",
    "        if not file:\n",
    "            file = self.student_dir_name\n",
    "        return super().get_xattr(attribute, file)\n",
    "    \n",
    "    @property\n",
    "    def class_of(self):\n",
    "        return self._class_of\n",
    "    \n",
    "    @class_of.setter\n",
    "    def class_of(self, class_of):\n",
    "        '''string representation of projected graduation date in format: \"ClassOf-YYYY\"\n",
    "        \n",
    "        Properties Set:\n",
    "            path_parts(`dict`): dictionary of component parts of path'''\n",
    "        if not class_of:\n",
    "            self._class_of = None\n",
    "        else:\n",
    "            # attempt to coerce strings from cSV file into type int\n",
    "            class_of = int(class_of)\n",
    "            if not isinstance(class_of, int):\n",
    "                raise TypeError('class_of must be of type `int`')\n",
    "        self.path_parts['ClassOf'] = f'ClassOf-{class_of}'\n",
    "        self._class_of = class_of\n",
    "        \n",
    "    @property\n",
    "    def name(self):\n",
    "        return self._name\n",
    "    \n",
    "    @name.setter\n",
    "    def name(self, name):\n",
    "        '''string representation of \"Last, First\" names\n",
    "        \n",
    "        Properties Set:\n",
    "            path_parts(`dict`): dictionary of component parts of path'''\n",
    "        if not name:\n",
    "            self._name = None\n",
    "        else:\n",
    "            if not isinstance (name, str):\n",
    "                raise TypeError('name must be of type `str`')\n",
    "        self.path_parts['name'] = name\n",
    "        self._name = name\n",
    "        \n",
    "    @property\n",
    "    def id_number(self):\n",
    "        return self._id_number\n",
    "    \n",
    "    @id_number.setter\n",
    "    def id_number(self, number):\n",
    "        '''integer of student id number\n",
    "        \n",
    "        Properties Set:\n",
    "            path_parts(`dict`): dictionary of component parts of path'''\n",
    "        if not number:\n",
    "            self._id_number = None\n",
    "        else:\n",
    "            # try to coerce number into type int\n",
    "            number = int(number)\n",
    "            if not isinstance (number, int):\n",
    "                raise TypeError('id_number must be of type `int`')\n",
    "        self.path_parts['id_number'] = number\n",
    "        self._id_number = number\n",
    "\n",
    "    @property\n",
    "    def student_dir_name(self):\n",
    "        '''full absolute path to student directory in format:\n",
    "            ClassOf-YYYY/Last, First - NNNNNNN'''\n",
    "        d = f\"/{self.path_parts['ClassOf']}/{self.path_parts['name']} - {self.path_parts['id_number']}\"\n",
    "        if self.path:\n",
    "            # not sure why this is needed, but any joining of self.root/Path(d) fails\n",
    "            d = f'{str(self.path)}/{d}'\n",
    "        return Path(d)\n",
    "    \n",
    "    # method for checking for similarly named student folders in this ClassOf folder\n",
    "    def check_similar(self):\n",
    "        '''check for similarly named directories based on student id number \n",
    "        within the path/ClassOf/ directory\n",
    "        \n",
    "        Properties Set:\n",
    "            self.matches(`dict`): dictionary of similar directories\n",
    "        Returns:\n",
    "            `bool`: True if matching directories found'''\n",
    "        similar = False\n",
    "        matches = {}\n",
    "        for i in self.student_dir_name.parent.glob(f\"*{self.path_parts['id_number']}*\"):\n",
    "            match_id = self.get_xattr('user.drive.id', self.student_dir_name.parent/i)\n",
    "            if i.absolute().is_dir():\n",
    "                url = '/'.join((self._dir_base, match_id[0]))\n",
    "            else:\n",
    "                url = '/'.join((self._file_base, match_id[0]))\n",
    "            matches[str(i)] = url\n",
    "        self.matches = matches\n",
    "        if matches:\n",
    "            similar = True\n",
    "        return similar\n",
    "\n",
    "    def mkdir(self, path=None, exist_ok=False, parents=True, kwargs={}):\n",
    "        '''make a google drive directory using pathlib.Path().mkdir()\n",
    "        \n",
    "        Args:\n",
    "            path(`str` or `Path`): defaults to self.student_dir_name\n",
    "            exist_ok(`bool`): True - do not raise error if directory exists\n",
    "            parents(`bool`): True - create parents if they do not exist\n",
    "            kwargs({}): pathlib.Path() kwargs\n",
    "            \n",
    "        Returns:\n",
    "            list[str]: google drive object ID string'''\n",
    "        if not path:\n",
    "            path = self.student_dir_name\n",
    "        logging.debug(f'calling super().mkdir(path={path})')\n",
    "        val = super().mkdir(path=path, exist_ok=exist_ok, parents=parents, **kwargs)\n",
    "        return val\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_data(csv_list, expected_headers, header_map):\n",
    "    '''validate list items for proper data types\n",
    "         naievely attempts to coerce strings from CSV into expected_header types\n",
    "         returns a tuple of list of rows that were successfully coerced and those\n",
    "         that could not be coerced\n",
    "    \n",
    "    Args:\n",
    "        csv_list(`list` of `list`): csv as a nested list [['h1', 'h2'], ['item', 'item2']]\n",
    "        expected_headers(`dict`): {'literal_header': type} {'ClassOf':, int, 'Name', str}\n",
    "        header_map(`dict`): map of list index for each header {'h1': 0, 'h2': 5, 'hN': i}\n",
    "        \n",
    "    Returns:\n",
    "        (`tuple` of `list`): (valid_rows, invalid_rows)\n",
    "    '''\n",
    "    valid = []\n",
    "    invalid = []\n",
    "\n",
    "    for row in csv_list[1:]:\n",
    "        good_row = True\n",
    "        for k in expected_headers.keys():\n",
    "            # test for coercable types\n",
    "            try:\n",
    "                test = expected_headers[k](row[header_map[k]])\n",
    "            except ValueError:\n",
    "#                 do_exit(f'Bad student.export: {k} contained {row[header_map[k]]}\\ncannot continue. Please try running the export again.')\n",
    "                logging.warning(f'{row}')\n",
    "                logging.warning(f'Bad student.export: column \"{k}\" contained \"{row[header_map[k]]}\"--this should be {(expected_headers[k])}')\n",
    "                invalid.append(row)\n",
    "                good_row = False\n",
    "                break\n",
    "        if  good_row:\n",
    "            valid.append(row)\n",
    "        \n",
    "    return valid, invalid\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def writeCSV(studentFolders, csvHeaders, output_path):\n",
    "#     logger = logging.getLogger(__name__)\n",
    "#     logger.debug('writing csv output at path: {}'.format(output_path))\n",
    "    \n",
    "#     output_path = os.path.expanduser(output_path)\n",
    "#     htmlFormat = '<a href={}>Right click link and *Open Link in New Tab* to view student folder</a>'\n",
    "#     csvOutput_list = []\n",
    "#     if not csvHeaders:\n",
    "#         csvHeaders = ['webViewLink',\n",
    "#                       'LastFirst',\n",
    "#                       'classOf', \n",
    "#                       'student_number']\n",
    "#     csvOutput_list.append(csvHeaders)\n",
    "#     for student in studentFolders:\n",
    "#         if studentFolders[student]:\n",
    "#             thisStudent = []\n",
    "#             for header in csvHeaders:\n",
    "#                 if header in studentFolders[student]:\n",
    "#                     if header == 'webViewLink':\n",
    "#                         thisStudent.append(htmlFormat.format(studentFolders[student][header]))\n",
    "#                     else:\n",
    "#                         thisStudent.append(studentFolders[student][header])                \n",
    "#                         if len(thisStudent) == len(csvHeaders):\n",
    "#                             csvOutput_list.append(thisStudent)\n",
    "    \n",
    "#     logger.debug('Writing rows:')\n",
    "#     try:\n",
    "# #         with open(output_path, 'wb') as f:\n",
    "#         with open(output_path, 'w') as f:\n",
    "#             writer = csv.writer(f,\n",
    "#                     quoting = csv.QUOTE_NONE,\n",
    "#                     delimiter='\\t')\n",
    "#             for each in csvOutput_list:\n",
    "#                 logging.debug(each)\n",
    "#                 writer.writerow(each)\n",
    "# #             writer.writerows(csvOutput_list)\n",
    "#     except Exception as e:\n",
    "#         logger.error('error writing CSV file: {}; {}'.format(output_path, e))\n",
    "#         return(None)\n",
    "#     return(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_handler(handler=None, new_level=None):\n",
    "    '''adjust a logging handler\n",
    "    \n",
    "    Args:\n",
    "        handler(`str`): partial string in handler name - if none, returns list of all handlers attached to root\n",
    "            '*' adjusts all handlers to new_level\n",
    "        new_level(`str`): DEBUG, INFO, WARNING, ERROR\n",
    "    \n",
    "    Returns:\n",
    "        `list`: list of handlers and levels currently set'''\n",
    "    if not handler:\n",
    "        return(logging.getLogger().handlers)\n",
    "    \n",
    "    my_handler = None    \n",
    "    for index, val in enumerate(logging.getLogger().handlers):\n",
    "        if handler == '*':\n",
    "            my_handler = logging.getLogger().handlers[index]\n",
    "        else:\n",
    "            if handler in str(val):\n",
    "                my_handler = logging.getLogger().handlers[index]\n",
    "        if my_handler:\n",
    "            logging.info(f'setting {str(my_handler)} to {new_level}')\n",
    "            my_handler.setLevel(new_level)\n",
    "        else:\n",
    "            logging.warning(f'handler: \"{handler}\" not found')\n",
    "        \n",
    "    return logging.getLogger().handlers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_cmdargs():\n",
    "    '''set known command line arguments and parse sys.argv\n",
    "    \n",
    "    Returns:\n",
    "        `dict`: nested dictionary of command line arguments that matches strcture of .ini file'''\n",
    "    args = ArgConfigParse.CmdArgs()\n",
    "    args.add_argument('-s', '--student_export', ignore_none=False, metavar='/path/to/student.export.csv', \n",
    "                      type=str, dest='student_export', help='Export from PowerSchool containing: LastFirst, ClassOf, Student_Number')\n",
    "\n",
    "    args.add_argument('-g', '--google_drive', ignore_none=True, metavar='/Volumes/GoogleDrive/Shared drives/ASH Cum Folders/folder/',\n",
    "                      type=str, dest='main__drive_path', help='Full path to Google Drive Shared Drive containing cumulative files')\n",
    "\n",
    "    args.add_argument('-l', '--log_level', ignore_none=True, metavar='ERROR, WARNING, INFO, DEBUG', \n",
    "                      type=str, dest='main__log_level', help='Logging level -- Default: WARNING')\n",
    "\n",
    "    args.parse_args()\n",
    "    return args.nested_opts_dict                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_config(files):\n",
    "    '''parse .ini files\n",
    "    \n",
    "    Args:\n",
    "        files(`list`): list of files to parse\n",
    "    \n",
    "    Returns:\n",
    "        `dict`: nested dict of configuration'''\n",
    "    parser = ArgConfigParse.ConfigFile(config_files=files, ignore_missing=True)\n",
    "    parser.parse_config()\n",
    "    \n",
    "    return parser.config_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_drive_path(drive_path=None):\n",
    "    '''check that path is a valid google drive path and contains the appropriate sentry file\n",
    "    \n",
    "    Args:\n",
    "        drive_path(`str`): path to google drive containg cummulative folders and sentry file\n",
    "    \n",
    "    Retruns:\n",
    "        `tuple` of `bool`, `str`: When true, drive is OK; when false, drive is not valid; str contains errors'''\n",
    "    # this is super redundant -- checks the following:\n",
    "    # * is a path\n",
    "    # * is a google drive path\n",
    "    # * if sentry file exists\n",
    "    # this may be a good idea considering how some users have run into many problems with this\n",
    "\n",
    "    drive_ok = True\n",
    "    msg = None\n",
    "    if not drive_path:\n",
    "        logging.info('no google drive specified')\n",
    "        drive_ok = False\n",
    "        msg = 'No Google Drive specified'\n",
    "        return drive_ok, msg\n",
    "    else:\n",
    "        drive_path = Path(drive_path)\n",
    "    \n",
    "    if not drive_path.exists():\n",
    "        logging.warning(f'specified path \"{drive_path}\" does not exist')\n",
    "        drive_ok = False\n",
    "        msg = f'The Google Drive \"{drive_path}\" does not appear to exist on Google Drive'\n",
    "        return drive_ok, msg\n",
    "    else:\n",
    "        google_drive = gd_path(drive_path)\n",
    "    \n",
    "    try:\n",
    "        google_drive.get_xattr('user.drive.id')\n",
    "    except ChildProcessError as e:\n",
    "        logging.warning(f'specified path \"{drive_path}\" is not a Google Drive path')\n",
    "        msg = f'The Google Drive \"{drive_path}\" does not appear to be a valid google Shared Drive'\n",
    "        drive_ok = False\n",
    "        return drive_ok, msg\n",
    "\n",
    "    sentry_file = constants.sentry_file    \n",
    "    sentry_file_path = drive_path/Path(sentry_file)\n",
    "    \n",
    "    if not sentry_file_path.is_file():\n",
    "        logging.warning(f'sentry file is missing in specified path \"{drive_path}\"')\n",
    "        msg = f'''The chosen google shared drive \"{drive_path}\"\n",
    "does not appear to be a Cumulative Student Folder. \n",
    "\n",
    "The file: \"{sentry_file}\" is missing. \n",
    "If you are sure {drive_path} is correct, \n",
    "please contact IT Support and askfor help. \n",
    "\n",
    "Please screenshot or copy this entire text below and provide it to IT Support.\n",
    "\n",
    "###############################################################################\n",
    "Run the command below from the terminal of the user that submitted this ticket.\n",
    "This command will create the necessary files for this script. \n",
    "\n",
    "Confirm that {drive_path} is the correct\n",
    "Google Shared Drive for Cumulative Student Folders BEFORE proceeding.\n",
    "     $ touch {drive_path}/{sentry_file}'''\n",
    "        drive_ok = False\n",
    "    \n",
    "    \n",
    "    \n",
    "    return drive_ok, msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():    \n",
    "    # set the local logger\n",
    "    logger = logging.getLogger(__name__)\n",
    "\n",
    "    # base configuration fle\n",
    "    config_file = Path(constants.config_file)\n",
    "    # user config file (~/.config/app_name/app.ini)\n",
    "    user_config_path = Path(constants.user_config_path)\n",
    "    \n",
    "    # if the user configuration file is missing set to True & create later at end\n",
    "    update_user_config = user_config_path.exists\n",
    "    logging.debug(f'update_user_config: {update_user_config}')\n",
    "\n",
    "    # parse command line and config files\n",
    "    cmd_args_dict = parse_cmdargs()\n",
    "    cfg_files_dict = read_config([constants.config_file, constants.user_config_path])\n",
    "\n",
    "    # merge the command line arguments and the config files; cmd line overwrites files\n",
    "    config = ArgConfigParse.merge_dict(cfg_files_dict, cmd_args_dict)\n",
    "\n",
    "    # adjust the logging levels if needed\n",
    "    if config['main']['log_level']:\n",
    "        ll = config['main']['log_level']\n",
    "        if ll in (['DEBUG', 'INFO', 'WARNING', 'ERROR']):\n",
    "            logging.root.setLevel(ll)\n",
    "            handlers = adjust_handler('*', ll)\n",
    "            logging.debug(f'adjusted log levels: {handlers}')\n",
    "        else:\n",
    "            logging.warning(f'unknown or invalid log_level: {ll}')\n",
    "    \n",
    "    # load file constants\n",
    "    expected_headers = constants.expected_headers\n",
    "    \n",
    "    # try to confirm created files N times before giving up\n",
    "    confirm_retry = constants.confirm_retry\n",
    "    \n",
    "    #  wait N seconds for first try, N*retry for each subsiquent retry\n",
    "    base_wait = constants.base_wait\n",
    "    \n",
    "    student_dirs = constants.student_dirs\n",
    "        \n",
    "    # get csv_file and drive_path from the command line\n",
    "    try:\n",
    "        csv_file = Path(config['__cmd_line']['student_export'])\n",
    "    except TypeError:\n",
    "        logging.info('No student export file specified on command line')\n",
    "        csv_file = None\n",
    "        \n",
    "    \n",
    "    # check drive path is a google drive path\n",
    "    drive_path = config['main']['drive_path']\n",
    "    drive_status = check_drive_path(drive_path)\n",
    "    \n",
    "    if not drive_status[0]:\n",
    "        do_exit(sentry_status[1], 1)\n",
    "        # consider prompting user at this point to enter a valid drive\n",
    "    \n",
    "    # read CSV into a list\n",
    "    if not csv_file:\n",
    "        do_exit('No student export CSV file specified. Exiting.', 1)\n",
    "    try:\n",
    "        csv_list = csv_to_list(csv_file)\n",
    "    except (FileNotFoundError, OSError, IOError, TypeError) as e:\n",
    "        logging.error(f'could not read csv file: {csv_file}')\n",
    "        logging.error(f'{e}')\n",
    "        do_exit(e, 1)\n",
    "    \n",
    "    # map the expecdted headers to the appropriate columns\n",
    "    header_map, missing_headers = map_headers(csv_list, expected_headers.keys())\n",
    "    \n",
    "    # error out if there are any missing headers\n",
    "    if len(missing_headers) > 0:\n",
    "        do_exit(f'{csv_file.name} is missing one or more headers:\\n\\t{missing_headers}\\nprogram cannot continue', 1)\n",
    "    \n",
    "    # validate the csv list\n",
    "    valid_rows, invalid_rows = validate_data(csv_list, expected_headers, header_map)\n",
    "\n",
    "    # dictionary to record created directories\n",
    "    directories = {'created': [], 'skipped': [], 'invalid': invalid_rows, \n",
    "                   'confirmed': [], 'failed': []}\n",
    "    for row in valid_rows:\n",
    "        name = row[header_map['LastFirst']]\n",
    "        class_of = row[header_map['ClassOf']]\n",
    "        id_number = row[header_map['Student_Number']]\n",
    "        \n",
    "        s_path = student_path(path=drive_path,\n",
    "                              name=name, \n",
    "                              class_of=class_of, \n",
    "                              id_number=id_number)\n",
    "        \n",
    "        # check if there already exists a directory with the student number\n",
    "        if s_path.check_similar():\n",
    "            # flag those that have multiple entries\n",
    "            if len(s_path.matches) > 1:\n",
    "                logging.warning(f'multiple directories exist in {class_of} for student number {id_number}')\n",
    "                directories['skipped'].append((s_path, 'multiple'))\n",
    "            # flag those that already exist for auditing purposes\n",
    "            else:\n",
    "                logging.info(f'skipped {class_of}/{name} - {id_number}: folder exists')\n",
    "                directories['skipped'].append((s_path, 'exists'))\n",
    "\n",
    "                \n",
    "        else:\n",
    "            # create the directory and try to handle errors as needed\n",
    "            try:\n",
    "                s_path.mkdir(parents=True)\n",
    "            except FileExistsError as e:\n",
    "                logging.error(f'{s_path.student_dir_name} exists')\n",
    "                directories['skipped'].append((s_path, 'exists'))\n",
    "            except OSError as e:\n",
    "                logging.error(f'Could not create {s_path.student_dir_name}: {e}')\n",
    "                directories['skipped'].append((s_path, 'failed'))\n",
    "            else:\n",
    "                directories['created'].append(s_path)\n",
    "\n",
    "# inject a bad entry to test checks at end\n",
    "#     directories['created'].append(student_path(path='/Volumes/GoogleDrive/Shared drives/IT Blabla I/spam_eggs_spam',\n",
    "#                                                name='Eggs, Green', class_of=1000, id_number=123456))\n",
    "    \n",
    "    \n",
    "    # double check that drectories were created and properly synced to google drive\n",
    "    for i in range(0, confirm_retry):\n",
    "        if len(directories['created']) > 0:\n",
    "            wait = i * base_wait\n",
    "        dirs_to_check = directories['created']\n",
    "        for each in dirs_to_check:\n",
    "            logging.info(f'checking: {each}')\n",
    "            if each.confirm():\n",
    "                logging.debug(f'confirmed: {each}')\n",
    "                directories['confirmed'].append(each)\n",
    "                directories['created'].remove(each)\n",
    "            \n",
    "        # loop over the created directories N times with a longer delay each time\n",
    "        # check that everything is confirmed uploaded; if it is not after Nth time, \n",
    "        # log as 'failed'\n",
    "        if len(directories['created']) > 0:\n",
    "            logging.info(f'sleeping for {wait} seconds and checking dirs again')\n",
    "            time.sleep(wait)\n",
    "        else:\n",
    "            logging.info('all created directories confirmed')\n",
    "            break\n",
    "\n",
    "    \n",
    "    if len(directories['created']) > 0:\n",
    "        directories['failed'] = directories['created']\n",
    "        directories['created'] = []\n",
    "#         dirs_to_check = directories['created']\n",
    "#         # migrate the created to the failed\n",
    "#         for each in dirs_to_check:\n",
    "#             directories['failed'].append(directories['created'].pop())\n",
    "    \n",
    "    # add better reporting on total attempted, created, skipped, failed, confirmed\n",
    "    total = 0\n",
    "    for each in directories:\n",
    "        total = total + len(each)\n",
    "    \n",
    "    # run over skipped and report those that have multiple directories and the path\n",
    "    # user should deal with these.\n",
    "    skipped = len(directories['skipped'])\n",
    "    failed = len(directories['failed'])\n",
    "    confirmed = len(directories['confirmed'])\n",
    "    invalid = len(directories['invalid'])\n",
    "    \n",
    "    multiple = [i[0] for i in directories['skipped'] if i[1] =='multiple' ]\n",
    "\n",
    "    print('created new:')\n",
    "    for each in directories['confirmed']:\n",
    "        print(each.webview_link)\n",
    "        \n",
    "        \n",
    "    print('confirmed exist:')\n",
    "    for each in directories['skipped']:\n",
    "        print(each[0].webview_link)\n",
    "            \n",
    "    print('Students with multiple portfolio folders:')\n",
    "    for each in multiple:\n",
    "        print('The students below have multiple cumulative folders. This is likely due to a name change.')\n",
    "        print('YOU MUST PICK **ONE** FOLDER AND MOVE ALL THE DATA INTO THAT ONE FOLDER AND DELETE THE OTHERS.\\nTHIS IS A MAJOR PROBLEM.')\n",
    "        if each.check_similar:\n",
    "            print(f'{each.name} has {len(each.matches)} folders:')\n",
    "            for folder in each.matches:\n",
    "                print(f'\\t{each.matches[folder]}')\n",
    "        \n",
    "    \n",
    "        \n",
    "    \n",
    "    if update_user_config:\n",
    "        try:\n",
    "            logging.info(f'updating user configuration file: {user_config_path}')\n",
    "            ArgConfigParse.write(config, user_config_path, create=True)\n",
    "        except Exception as e:\n",
    "            m = f'Error updating user configuration file: {e}'\n",
    "            do_exit(m, 1)\n",
    "\n",
    "            \n",
    "    # add summary of actions and errors\n",
    "    # create csv output for adding portfolio links into PS SIS\n",
    "    return directories\n",
    "    \n",
    "\n",
    "    # cleanup\n",
    "    # handle invalid_rows -- notify user of issues\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created new:\n",
      "confirmed exist:\n",
      "https://drive.google.com/drive/folders/1S1va9b9RtZ8dqs3Mhm6qtTdTR5yU4ssT\n",
      "https://drive.google.com/drive/folders/1S8VvqJuIsbJ379tO_IKVcAbTj93pyjgB\n",
      "https://drive.google.com/drive/folders/14LSP1JHhvr1pggRqwZ2Ec8QB8VdhcayA\n",
      "https://drive.google.com/drive/folders/1S7X1-sJH63Xo8Qi6YydWTOL84LAzefNB\n",
      "https://drive.google.com/drive/folders/1S2o8u7_dFeGkMDIoK_pM2xLhZrCHq4Uw\n",
      "Students with multiple portfolio folders:\n",
      "The students below have multiple cumulative folders. This is likely due to a name change.\n",
      "YOU MUST PICK **ONE** FOLDER AND MOVE ALL THE DATA INTO THAT ONE FOLDER AND DELETE THE OTHERS.\n",
      "THIS IS A MAJOR PROBLEM.\n",
      "Wanja, Michelle has 3 folders:\n",
      "\thttps://drive.google.com/drive/folders//1S1va9b9RtZ8dqs3Mhm6qtTdTR5yU4ssT\n",
      "\thttps://drive.google.com/drive/folders//1SNG5SkvH5XQ4JKQItbpCjN4eQ8JyS5mr\n",
      "\thttps://drive.google.com/drive/folders//1SQxeOE5m0Q7De1sM6AzlzY_mK9Ntn6nN\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    f = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    skipped = len(directories['skipped'])\n",
    "    failed = len(directories['failed'])\n",
    "    confirmed = len(directories['confirmed'])\n",
    "    invalid = len(directories['invalid'])\n",
    "    multiple = [i[0] for i in skipped if i[1] =='multiple' ]\n",
    "\n",
    "    print('created new:')\n",
    "    for each in directories['confirmed']:\n",
    "        print(each.webview_link)\n",
    "        \n",
    "        \n",
    "    print('confirmed exist:')\n",
    "    for each in directories['skipped']:\n",
    "        print(each[0].webview_link)\n",
    "            \n",
    "    print('Students with multiple portfolio folders:')\n",
    "    for each in multiple:\n",
    "        if each.check_similar:\n",
    "            print(each.name)\n",
    "            for folder in each.matches:\n",
    "                print(each.matches[folder])\n",
    "        \n",
    "    print('YOU MUST MERGE THESE SO THERE IS ONLY FOLDER FOR EACH STUDENT. THIS IS A MAJOR PROBLEM.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = f['skipped']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "mult = [m[0] for m in f['skipped'] if m[1] =='multiple' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[student_path(/Volumes/GoogleDrive/Shared drives/IT Blabla I/Student Cumulative Folders (AKA Student Portfolios)/ClassOf-2023/Wanja, Michelle - 505586)]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = s[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = m[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.check_similar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wanja, Michelle\n",
      "https://drive.google.com/drive/folders//1S1va9b9RtZ8dqs3Mhm6qtTdTR5yU4ssT\n",
      "https://drive.google.com/drive/folders//1SNG5SkvH5XQ4JKQItbpCjN4eQ8JyS5mr\n",
      "https://drive.google.com/drive/folders//1SQxeOE5m0Q7De1sM6AzlzY_mK9Ntn6nN\n"
     ]
    }
   ],
   "source": [
    "print(e.name)\n",
    "for s in e.matches:\n",
    "    print(e.matches[s])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.argv.append('-g')\n",
    "sys.argv.append('/Volumes/GoogleDrive/Shared drives/IT Blabla I/Student Cumulative Folders (AKA Student Portfolios)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.argv.append('-g')\n",
    "sys.argv.append('/xVolumes/GoogleDrive/Shared drives/IT Blabla I/Student Cumulative Folders (AKA Student Portfolios)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.argv.append('-s')\n",
    "sys.argv.append('./student.export.text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.argv.append('-l')\n",
    "sys.argv.append('INFO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sys.argv.pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sys.argv.append('-s')\n",
    "# sys.argv.append('./student.export.csv.text')\n",
    "# # f = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.argv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sys.argv.append('-g')\n",
    "# sys.argv.append('/Volumes/GoogleDrive/Shared drives/IT Blabla I/Student Cumulative Folders (AKA Student Portfolios)')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "portfolioCreator-alMouNtK",
   "language": "python",
   "name": "portfoliocreator-almountk"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
