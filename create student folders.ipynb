{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "%reload_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import ArgConfigParse\n",
    "from pathlib import Path\n",
    "import os\n",
    "import fnmatch\n",
    "import multiprocessing\n",
    "import time\n",
    "import csv\n",
    "import sys\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)\n",
    "logger.root.setLevel('DEBUG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_files(directory, pattern):\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for basename in files:\n",
    "            if fnmatch.fnmatch(basename, pattern):\n",
    "                filename = Path(root)/Path(basename)\n",
    "                yield filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doExit(message='unknown error in unknown module: BSoD!', exit_level=0, testing=False):\n",
    "    logger = logging.getLogger(__name__)\n",
    "    \n",
    "    logger.info('exiting before program completion with exit code {}'.format(exit_level))\n",
    "    print('progam exited due to errors -- see the logs')\n",
    "    if not testing:\n",
    "        sys.exit(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tick(n=10):\n",
    "    for i in range(n):\n",
    "        print(f'tick: {i} of {n-1}')\n",
    "        time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapHeaders(file_csv, expected_headers=[]):\n",
    "    '''map an expected list of header values to their position in a csv\n",
    "    accepts:\n",
    "        file_csv (filename) - list containing CSV\n",
    "        expected_headers (list) - list of headers to search for, ignoring all others\n",
    "    '''\n",
    "    logger = logging.getLogger(__name__)\n",
    "    logger.debug('mapping headers')\n",
    "    \n",
    "    \n",
    "    missing_headers = []\n",
    "    header_map = {}\n",
    "        \n",
    "    try:\n",
    "        csvHeader = file_csv[0]\n",
    "    except IndexError as e:\n",
    "        logger.warning('csv empty: {}'.format(e))\n",
    "        return(False)\n",
    "        \n",
    "    logger.debug('checking for missing headers')\n",
    "    for each in expected_headers:\n",
    "        if each not in csvHeader:\n",
    "            logger.debug('missing: {}'.format(each))\n",
    "            missing_headers.append(each)\n",
    "\n",
    "    if len(missing_headers) > 0:\n",
    "        logging.warning(f'missing expected headers: {missing_headers}')\n",
    "    for index, value in enumerate(csvHeader):\n",
    "        if value in expected_headers:\n",
    "            header_map[value] = index\n",
    "            \n",
    "    logger.debug('completed mapping headers')\n",
    "    return(header_map, missing_headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readCSV(csvFile):\n",
    "    csvFile = Path(csvFile).expanduser()\n",
    "    file_csv = []\n",
    "    try:\n",
    "        with open(csvFile, 'r') as file:\n",
    "            reader = csv.reader(file)\n",
    "            for row in reader:\n",
    "                file_csv.append(row)\n",
    "    except (OSError, IOError) as e:\n",
    "        logging.error(f'could not read file: {csvFile}')\n",
    "        logging.error(f'error: {e}')\n",
    "        return(False)\n",
    "    \n",
    "    return(file_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkSentry(sentryFile, basePath):\n",
    "    fileFound = False\n",
    "    sentryFile = Path(sentryFile)\n",
    "    basePath = Path(basePath)\n",
    "        \n",
    "    for filename in find_files(basePath, '*.txt'):\n",
    "        if sentryFile.name in filename.name:\n",
    "            logging.info(f'sentry file ({sentryFile}) found')\n",
    "            fileFound = filename.parent\n",
    "            break\n",
    "    if not fileFound:\n",
    "        logging.warning(f'sentry file ({sentryFile}) not found in {basePath}')\n",
    "    return(fileFound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createDirectories(studentCSV, headers, studentRoot, subDirs):\n",
    "    dirCheck = {}\n",
    "    logging.debug('creating student directories as needed')\n",
    "    for student in studentCSV[1:]:\n",
    "        LastFirst = student[headers['LastFirst']]\n",
    "        ClassOf = 'ClassOf-'+student[headers['ClassOf']]\n",
    "        Student_Number = student[headers['Student_Number']]\n",
    "        studentDir = f'{LastFirst} - {Student_Number}'    \n",
    "        studentDir = studentRoot/ClassOf/studentDir\n",
    "        dirCheck[studentDir] = {}\n",
    "        for subDir in subDirs:\n",
    "            gradeLevelDir = studentDir/subDir\n",
    "            try:\n",
    "                gradeLevelDir.mkdir(parents=True)\n",
    "                action = 'created'\n",
    "                logging.debug(f'created: {gradeLevelDir}')\n",
    "            except (FileExistsError):\n",
    "                action = None\n",
    "            except Exception as e:\n",
    "                logging.error(e)\n",
    "                doExit(e, 1)\n",
    "                \n",
    "            \n",
    "            dirCheck[studentDir][subDir] = action\n",
    "    return(dirCheck)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### add this into the main()\n",
    "appName = constants.appName\n",
    "develName = constants.develName\n",
    "userPath = constants.userPath\n",
    "version = constants.version\n",
    "configFile = constants.configFile\n",
    "\n",
    "baseConfig = Path(configFile).resolve()\n",
    "userConfig = Path('~/.config/').expanduser()/userPath/configFile\n",
    "\n",
    "# create the user config files if missing\n",
    "if not userConfig.is_file():\n",
    "    logging.info(f'creating user config file: {userConfig}')\n",
    "    try:\n",
    "        userConfig.parent.mkdir(parents=True, exist_ok=True)\n",
    "        shutil.copy(baseConfig, userConfig)\n",
    "    except Exception as e:\n",
    "        doExit(f'failed to create user config file: {e}', 1)\n",
    "        \n",
    "\n",
    "configParser = ArgConfigParse.ConfigFile([baseConfig, userConfig])\n",
    "try:\n",
    "    configParser.parse_config()\n",
    "except Exception as e:\n",
    "    doExit(f'error reading config files: {e}')\n",
    "\n",
    "config = configParser.config_dict\n",
    "if not config['main']['google_drive']:\n",
    "    print('get google drive here')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    ## FIXME move this into configuration/interrogation\n",
    "    basePath = Path('/Volumes/GoogleDrive/Shared drives/IT Blabla I/')\n",
    "#     basePath = Path('/Volumes/GoogleDrive/Shared drives/ASH Student Cumulative Folders')\n",
    "    #basePath = Path('/Volumes/GoogleDrive/Shared drives/')\n",
    "    sentryFile = 'sentryFile_DO_NOT_REMOVE.txt'\n",
    "    csvFile = './student.export.text'\n",
    "\n",
    "    subDirs = ['00-Preschool', '00-Transition Kindergarten', '00-zKindergarten', \n",
    "               '01-Grade', '02-Grade', '03-Grade', '04-Grade', '05-Grade', '06-Grade', \n",
    "               '07-Grade', '08-Grade', '09-Grade', '10-Grade', '11-Grade', '12-Grade']\n",
    "    \n",
    "    expectedHeaders = ['ClassOf', 'Student_Number', 'LastFirst']\n",
    "    \n",
    "#     config = \n",
    "\n",
    "    \n",
    "    ## FIXME - Add a timeout around this\n",
    "    studentRoot = checkSentry(sentryFile, basePath)\n",
    "    if not studentRoot:\n",
    "        logging.warning(f'This Google Shared Drive ({basePath}) does not appear to include the required sentry file: {sentryFile}')\n",
    "        logging.warning('Try selecting a different Google Shared Drive.')\n",
    "        doExit()\n",
    "    \n",
    "    ## FIXME handle false returns gracefully\n",
    "    studentCSV = readCSV(csvFile)\n",
    "    ## FIXME handle missing headers gracefully\n",
    "    headers, missing = mapHeaders(studentCSV, expectedHeaders)\n",
    "\n",
    "    log = createDirectories(studentCSV=studentCSV, headers=headers, studentRoot=studentRoot, subDirs=subDirs)\n",
    "    \n",
    "    \n",
    "    results = {}\n",
    "    actions = 0\n",
    "    for student in log:\n",
    "        created = 0\n",
    "        for subdir in log[student]:\n",
    "            if log[student][subdir]:\n",
    "                created += 1\n",
    "        results[student] = created\n",
    "    for each in results:\n",
    "        if results[each] > 0:\n",
    "            print(f'created or updated:\\n {each}\\n  created: {results[each]} folders')\n",
    "        else:\n",
    "            print(f'no action needed for:\\n {each}')    \n",
    "    return(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    f = main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # kill a sub process if it's taking too long to complete\n",
    "# p = multiprocessing.Process(target=tick, name='ticker', args=(3,))\n",
    "# p.start()\n",
    "\n",
    "# time.sleep(5)\n",
    "# if p.is_alive():\n",
    "#     print('tick is running; killing')\n",
    "#     p.terminate()\n",
    "# else:\n",
    "#     print('tick completed without the need to kill it')\n",
    "# p.join()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "portfolioCreator-alMouNtK",
   "language": "python",
   "name": "portfoliocreator-almountk"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
